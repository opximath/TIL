{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 데이터의 전처리\n",
    "- NLP(Natual Language Processing)는 자연어 처리라 불리며, 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 묘사할 수 있도록 연구하고 이를 구현하는 인공지능의 주요 분야 중 하나다.\n",
    "- 파이썬을 지원하는 한글 자연어 처리 패키지로 유명한 KoLNPy를 활용하여 진행\n",
    "- 추가로 Okt를 활용하여 형태소 분석을 진행할 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 이해\n",
    "### KoNLPy를 사용한 형태소 분석\n",
    "- 자연어 처리 방법 중 형태소 분석(Morphological Analysis)가 있음\n",
    "- 형태소 분석은 문법 규칙이나 사전 데이터에 근거해서 대화나 문장을 단어로 분할하고 각각에 품사를 부여하는 처리를 뜻함\n",
    "- 형태소란 그 언어에 있어서 의미가 있는 최소 단위를 뜻함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/6292880/\n",
      "2012-02-19T13 : 00 : 00 + 0900\n",
      "구형 Mac에서 금단의 파워 업! 최신 PC 나 소프트웨어를 한꺼번에 체크 [IT 플래시백]\n",
      "텔레비전이나 Twitter와 연계 할 수있는 PC 나 프로세서, 전환 PC 등 재미있는 PC가 속속 등장했다. 구형 Mac의 금단이라고도 할 수있는 파워 업 방법에서 NEC의 최신 PC, 화제의 ThinkPad X1 Hybrid, 새로운 보안 소프트웨어까지 한꺼번에 소개합니다.\n",
      "\n",
      "■ 인텔 SSD 520을 Mac에 장착! 구형 Mac은 얼마나 빨라질 것인가? (위)\n",
      "인텔이 최신 SSD '520 시리즈'를 출시했다. 현재 SSD 중에서도 최고의 성능을 자랑하는 이 제품을 구형 Mac의 고속화를 도모한다는 점에서 리뷰 해 보았다. 조금 색다른 리뷰가되지만, 어느 정도의 효과가 있는지, 기대가 크다.\n",
      "\n",
      "\n",
      "■ http : //itlifehack.jp/archives/6716997.html\n",
      "ThinkPad X1 Hybrid는 사용하는 CPU가 x86 (인텔 Core i 등)에서 ARM으로 전환가능한 하이브리드 PC, 하지만 이와 동시에 OS도 바뀐다.\n",
      "\n",
      "\n",
      "■ 초기 비용, 업데이트 비용 모두 무료! 저스트시스템, 도마뱀로그가 인상적인 보안 소프트웨어\n",
      "현재는 많은 사용자들이 PC에 보안 프로그램을 도입하고 있지만, 그 대부분은 매년 5,000 엔 정도 드는 업데이트 비용 과 그 절차에 대해 불만을 가지고있다. 유료 소프트웨어를 이용하는 사용자의 약 80 %는 무료 보안 소프트웨어를 알고 있음에도 불구하고, 성능면에서 뒤 떨어지는 게 아니냐는 불안에서 도입을 미루고 있는 상황이다.\n",
      "\n",
      "\n",
      "■ 텔레비전의 새로운 활용 방법을 제안! NEC의 봄 신상 PC는 TV와 Twitter를 연계\n",
      "NEC는 2012 년 2 월 14 일, 개인용 데스크톱 PC 인 'VALUESTAR \"시리즈 3 종류 16 모델을 2 월 16 일부터 판매한다고 발표했다. 신상품은 더 강력해진 녹화 기능 외에도 TV 시청 · 녹화 기능에 더해서 업계 최초로 인기 Twitter를 연계한 'SmartVision 트위트 플러스'를 추가하는 등 TV 컴퓨터 만의 기능을 탑재. 스마트 폰 홈 네트워크 대응도 강화하고, \"안심 간단 쾌적\"한 디지털 엔터테인먼트를 제안하여, 주요 모델에 대해 다음과 같이 기능 강화를 실시했다.\n",
      "\n",
      "\n",
      "■ 마치 축제같은 출하식! 렛츠 노트 SX1 출하 시작\n",
      "2 월 24 일에 발매되는 Let'snote SX1 / NX1의 출하식이 2 월 8 일 국내 제조 거점인 고베 공장에서 열렸다. 동사의 컴퓨터로는 처음실시하는 출하식으로, 이 제품에 얼마나 힘이 들어가 있는지 알 수있다.\n",
      "\n",
      "\n",
      "\n",
      "[엡손 정품 잉크] 잉크 카트리지 6 색 세트 IC6CL50\n",
      "엡손\n",
      "출판사 : Amazon.co.jp\n",
      "입소문을 본다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('./data/it-life-hack/it-life-hack-6292880.txt', encoding='utf-8')\n",
    "\n",
    "text = f.read()\n",
    "print(text)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('http://news.livedoor.com/article/detail/6292880/', 'URL')\n",
      "('\\n', 'Foreign')\n",
      "('2012-02', 'Number')\n",
      "('-', 'Punctuation')\n",
      "('19', 'Number')\n",
      "('T', 'Alpha')\n",
      "('13', 'Number')\n",
      "(':', 'Punctuation')\n",
      "('00', 'Number')\n",
      "(':', 'Punctuation')\n",
      "('00', 'Number')\n",
      "('+', 'Punctuation')\n",
      "('0900', 'Number')\n",
      "('\\n', 'Foreign')\n",
      "('구형', 'Noun')\n",
      "('Mac', 'Alpha')\n",
      "('에서', 'Josa')\n",
      "('금단', 'Noun')\n",
      "('의', 'Josa')\n",
      "('파워', 'Noun')\n",
      "('업', 'Noun')\n",
      "('!', 'Punctuation')\n",
      "('최신', 'Noun')\n",
      "('PC', 'Alpha')\n",
      "('나', 'Noun')\n",
      "('소프트웨어', 'Noun')\n",
      "('를', 'Josa')\n",
      "('한꺼', 'Verb')\n",
      "('번', 'Noun')\n",
      "('에', 'Josa')\n",
      "('체크', 'Noun')\n",
      "('[', 'Punctuation')\n",
      "('IT', 'Alpha')\n",
      "('플래시백', 'Noun')\n",
      "(']', 'Punctuation')\n",
      "('\\n', 'Foreign')\n",
      "('텔레비전', 'Noun')\n",
      "('이나', 'Josa')\n",
      "('Twitter', 'Alpha')\n",
      "('와', 'Verb')\n",
      "('연', 'Modifier')\n",
      "('계', 'Noun')\n",
      "('할', 'Verb')\n",
      "('수', 'Noun')\n",
      "('있는', 'Adjective')\n",
      "('PC', 'Alpha')\n",
      "('나', 'Noun')\n",
      "('프로세서', 'Noun')\n",
      "(',', 'Punctuation')\n",
      "('전환', 'Noun')\n",
      "('PC', 'Alpha')\n",
      "('등', 'Noun')\n",
      "('재미있는', 'Adjective')\n",
      "('PC', 'Alpha')\n",
      "('가', 'Verb')\n",
      "('속속', 'Adverb')\n",
      "('등장', 'Noun')\n",
      "('했다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('구형', 'Noun')\n",
      "('Mac', 'Alpha')\n",
      "('의', 'Noun')\n",
      "('금단', 'Noun')\n",
      "('이라고도', 'Josa')\n",
      "('할', 'Verb')\n",
      "('수', 'Noun')\n",
      "('있는', 'Adjective')\n",
      "('파워', 'Noun')\n",
      "('업', 'Noun')\n",
      "('방법', 'Noun')\n",
      "('에서', 'Josa')\n",
      "('NEC', 'Alpha')\n",
      "('의', 'Noun')\n",
      "('최신', 'Noun')\n",
      "('PC', 'Alpha')\n",
      "(',', 'Punctuation')\n",
      "('화제', 'Noun')\n",
      "('의', 'Josa')\n",
      "('ThinkPad', 'Alpha')\n",
      "('X', 'Alpha')\n",
      "('1', 'Number')\n",
      "('Hybrid', 'Alpha')\n",
      "(',', 'Punctuation')\n",
      "('새로운', 'Adjective')\n",
      "('보안', 'Noun')\n",
      "('소프트웨어', 'Noun')\n",
      "('까지', 'Josa')\n",
      "('한꺼', 'Verb')\n",
      "('번', 'Noun')\n",
      "('에', 'Josa')\n",
      "('소개', 'Noun')\n",
      "('합니다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('\\n\\n', 'Foreign')\n",
      "('■', 'Foreign')\n",
      "('인텔', 'Noun')\n",
      "('SSD', 'Alpha')\n",
      "('520', 'Number')\n",
      "('을', 'Josa')\n",
      "('Mac', 'Alpha')\n",
      "('에', 'Josa')\n",
      "('장착', 'Noun')\n",
      "('!', 'Punctuation')\n",
      "('구형', 'Noun')\n",
      "('Mac', 'Alpha')\n",
      "('은', 'Noun')\n",
      "('얼마나', 'Noun')\n",
      "('빨라질', 'Adjective')\n",
      "('것', 'Noun')\n",
      "('인가', 'Josa')\n",
      "('?', 'Punctuation')\n",
      "('(', 'Punctuation')\n",
      "('위', 'Noun')\n",
      "(')', 'Punctuation')\n",
      "('\\n', 'Foreign')\n",
      "('인텔', 'Noun')\n",
      "('이', 'Josa')\n",
      "('최신', 'Noun')\n",
      "('SSD', 'Alpha')\n",
      "(\"'\", 'Punctuation')\n",
      "('520', 'Number')\n",
      "('시리즈', 'Noun')\n",
      "(\"'\", 'Punctuation')\n",
      "('를', 'Noun')\n",
      "('출시', 'Noun')\n",
      "('했다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('현재', 'Noun')\n",
      "('SSD', 'Alpha')\n",
      "('중', 'Noun')\n",
      "('에서도', 'Josa')\n",
      "('최고', 'Noun')\n",
      "('의', 'Josa')\n",
      "('성능', 'Noun')\n",
      "('을', 'Josa')\n",
      "('자랑', 'Noun')\n",
      "('하는', 'Verb')\n",
      "('이', 'Noun')\n",
      "('제품', 'Noun')\n",
      "('을', 'Josa')\n",
      "('구형', 'Noun')\n",
      "('Mac', 'Alpha')\n",
      "('의', 'Noun')\n",
      "('고속', 'Noun')\n",
      "('화', 'Suffix')\n",
      "('를', 'Josa')\n",
      "('도모', 'Noun')\n",
      "('한다는', 'Modifier')\n",
      "('점', 'Noun')\n",
      "('에서', 'Josa')\n",
      "('리뷰', 'Noun')\n",
      "('해', 'Noun')\n",
      "('보았다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('조금', 'Noun')\n",
      "('색다른', 'Adjective')\n",
      "('리뷰', 'Noun')\n",
      "('가', 'Josa')\n",
      "('되지만', 'Verb')\n",
      "(',', 'Punctuation')\n",
      "('어느', 'Adverb')\n",
      "('정도', 'Noun')\n",
      "('의', 'Josa')\n",
      "('효과', 'Noun')\n",
      "('가', 'Josa')\n",
      "('있는지', 'Adjective')\n",
      "(',', 'Punctuation')\n",
      "('기대', 'Noun')\n",
      "('가', 'Josa')\n",
      "('크다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('\\n\\n\\n', 'Foreign')\n",
      "('■', 'Foreign')\n",
      "('http', 'Alpha')\n",
      "(':', 'Punctuation')\n",
      "('/', 'Foreign')\n",
      "('/itlifehack.jp/archives/6716997.html', 'URL')\n",
      "('\\n', 'Foreign')\n",
      "('ThinkPad', 'Alpha')\n",
      "('X', 'Alpha')\n",
      "('1', 'Number')\n",
      "('Hybrid', 'Alpha')\n",
      "('는', 'Verb')\n",
      "('사용', 'Noun')\n",
      "('하는', 'Verb')\n",
      "('CPU', 'Alpha')\n",
      "('가', 'Verb')\n",
      "('x', 'Alpha')\n",
      "('86', 'Number')\n",
      "('(', 'Punctuation')\n",
      "('인텔', 'Noun')\n",
      "('Core', 'Alpha')\n",
      "('i', 'Alpha')\n",
      "('등', 'Noun')\n",
      "(')', 'Punctuation')\n",
      "('에서', 'Josa')\n",
      "('ARM', 'Alpha')\n",
      "('으로', 'Josa')\n",
      "('전환', 'Noun')\n",
      "('가능한', 'Adjective')\n",
      "('하이브리드', 'Noun')\n",
      "('PC', 'Alpha')\n",
      "(',', 'Punctuation')\n",
      "('하지만', 'Conjunction')\n",
      "('이', 'Noun')\n",
      "('와', 'Josa')\n",
      "('동시', 'Noun')\n",
      "('에', 'Josa')\n",
      "('OS', 'Alpha')\n",
      "('도', 'Noun')\n",
      "('바뀐다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('\\n\\n\\n', 'Foreign')\n",
      "('■', 'Foreign')\n",
      "('초기', 'Noun')\n",
      "('비용', 'Noun')\n",
      "(',', 'Punctuation')\n",
      "('업데이트', 'Noun')\n",
      "('비용', 'Noun')\n",
      "('모두', 'Noun')\n",
      "('무료', 'Noun')\n",
      "('!', 'Punctuation')\n",
      "('저스트', 'Noun')\n",
      "('시스템', 'Noun')\n",
      "(',', 'Punctuation')\n",
      "('도마뱀', 'Noun')\n",
      "('로그', 'Noun')\n",
      "('가', 'Josa')\n",
      "('인상', 'Noun')\n",
      "('적', 'Suffix')\n",
      "('인', 'Josa')\n",
      "('보안', 'Noun')\n",
      "('소프트웨어', 'Noun')\n",
      "('\\n', 'Foreign')\n",
      "('현재', 'Noun')\n",
      "('는', 'Josa')\n",
      "('많은', 'Adjective')\n",
      "('사용자', 'Noun')\n",
      "('들', 'Suffix')\n",
      "('이', 'Josa')\n",
      "('PC', 'Alpha')\n",
      "('에', 'Josa')\n",
      "('보안', 'Noun')\n",
      "('프로그램', 'Noun')\n",
      "('을', 'Josa')\n",
      "('도입', 'Noun')\n",
      "('하고', 'Josa')\n",
      "('있지만', 'Adjective')\n",
      "(',', 'Punctuation')\n",
      "('그', 'Noun')\n",
      "('대부분', 'Noun')\n",
      "('은', 'Josa')\n",
      "('매년', 'Noun')\n",
      "('5,000', 'Number')\n",
      "('엔', 'Josa')\n",
      "('정도', 'Noun')\n",
      "('드는', 'Verb')\n",
      "('업데이트', 'Noun')\n",
      "('비용', 'Noun')\n",
      "('과', 'Noun')\n",
      "('그', 'Noun')\n",
      "('절차', 'Noun')\n",
      "('에', 'Josa')\n",
      "('대해', 'Noun')\n",
      "('불만', 'Noun')\n",
      "('을', 'Josa')\n",
      "('가지고있다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('유료', 'Noun')\n",
      "('소프트웨어', 'Noun')\n",
      "('를', 'Josa')\n",
      "('이용', 'Noun')\n",
      "('하는', 'Verb')\n",
      "('사용자', 'Noun')\n",
      "('의', 'Josa')\n",
      "('약', 'Noun')\n",
      "('80', 'Number')\n",
      "('%', 'Punctuation')\n",
      "('는', 'Verb')\n",
      "('무료', 'Noun')\n",
      "('보안', 'Noun')\n",
      "('소프트웨어', 'Noun')\n",
      "('를', 'Josa')\n",
      "('알', 'Noun')\n",
      "('고', 'Josa')\n",
      "('있음에도', 'Adjective')\n",
      "('불구', 'Noun')\n",
      "('하고', 'Josa')\n",
      "(',', 'Punctuation')\n",
      "('성능', 'Noun')\n",
      "('면', 'Noun')\n",
      "('에서', 'Josa')\n",
      "('뒤', 'Noun')\n",
      "('떨어지는', 'Verb')\n",
      "('게', 'Noun')\n",
      "('아니냐는', 'Adjective')\n",
      "('불안', 'Noun')\n",
      "('에서', 'Josa')\n",
      "('도입', 'Noun')\n",
      "('을', 'Josa')\n",
      "('미루고', 'Verb')\n",
      "('있는', 'Adjective')\n",
      "('상황', 'Noun')\n",
      "('이다', 'Josa')\n",
      "('.', 'Punctuation')\n",
      "('\\n\\n\\n', 'Foreign')\n",
      "('■', 'Foreign')\n",
      "('텔레비전', 'Noun')\n",
      "('의', 'Josa')\n",
      "('새로운', 'Adjective')\n",
      "('활용', 'Noun')\n",
      "('방법', 'Noun')\n",
      "('을', 'Josa')\n",
      "('제안', 'Noun')\n",
      "('!', 'Punctuation')\n",
      "('NEC', 'Alpha')\n",
      "('의', 'Noun')\n",
      "('봄', 'Noun')\n",
      "('신상', 'Noun')\n",
      "('PC', 'Alpha')\n",
      "('는', 'Verb')\n",
      "('TV', 'Alpha')\n",
      "('와', 'Verb')\n",
      "('Twitter', 'Alpha')\n",
      "('를', 'Noun')\n",
      "('연', 'Modifier')\n",
      "('계', 'Noun')\n",
      "('\\n', 'Foreign')\n",
      "('NEC', 'Alpha')\n",
      "('는', 'Verb')\n",
      "('2012', 'Number')\n",
      "('년', 'Noun')\n",
      "('2', 'Number')\n",
      "('월', 'Noun')\n",
      "('14', 'Number')\n",
      "('일', 'Noun')\n",
      "(',', 'Punctuation')\n",
      "('개인', 'Noun')\n",
      "('용', 'Noun')\n",
      "('데스크톱', 'Noun')\n",
      "('PC', 'Alpha')\n",
      "('인', 'Noun')\n",
      "(\"'\", 'Punctuation')\n",
      "('VALUESTAR', 'Alpha')\n",
      "('\"', 'Punctuation')\n",
      "('시리즈', 'Noun')\n",
      "('3', 'Number')\n",
      "('종류', 'Noun')\n",
      "('16', 'Number')\n",
      "('모델', 'Noun')\n",
      "('을', 'Josa')\n",
      "('2', 'Number')\n",
      "('월', 'Noun')\n",
      "('16', 'Number')\n",
      "('일', 'Noun')\n",
      "('부터', 'Josa')\n",
      "('판매', 'Noun')\n",
      "('한다고', 'Verb')\n",
      "('발표', 'Noun')\n",
      "('했다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('신', 'Modifier')\n",
      "('상품', 'Noun')\n",
      "('은', 'Josa')\n",
      "('더', 'Noun')\n",
      "('강력해진', 'Adjective')\n",
      "('녹화', 'Noun')\n",
      "('기능', 'Noun')\n",
      "('외', 'Noun')\n",
      "('에도', 'Josa')\n",
      "('TV', 'Alpha')\n",
      "('시청', 'Noun')\n",
      "('·', 'Punctuation')\n",
      "('녹화', 'Noun')\n",
      "('기능', 'Noun')\n",
      "('에', 'Josa')\n",
      "('더해서', 'Adjective')\n",
      "('업계', 'Noun')\n",
      "('최초', 'Noun')\n",
      "('로', 'Josa')\n",
      "('인기', 'Noun')\n",
      "('Twitter', 'Alpha')\n",
      "('를', 'Noun')\n",
      "('연', 'Modifier')\n",
      "('계', 'Noun')\n",
      "('한', 'Josa')\n",
      "(\"'\", 'Punctuation')\n",
      "('SmartVision', 'Alpha')\n",
      "('트', 'Noun')\n",
      "('위트', 'Noun')\n",
      "('플러스', 'Noun')\n",
      "(\"'\", 'Punctuation')\n",
      "('를', 'Noun')\n",
      "('추가', 'Noun')\n",
      "('하는', 'Verb')\n",
      "('등', 'Noun')\n",
      "('TV', 'Alpha')\n",
      "('컴퓨터', 'Noun')\n",
      "('만의', 'Josa')\n",
      "('기능', 'Noun')\n",
      "('을', 'Josa')\n",
      "('탑재', 'Noun')\n",
      "('.', 'Punctuation')\n",
      "('스마트', 'Noun')\n",
      "('폰', 'Noun')\n",
      "('홈', 'Noun')\n",
      "('네트워크', 'Noun')\n",
      "('대응', 'Noun')\n",
      "('도', 'Josa')\n",
      "('강화하고', 'Adjective')\n",
      "(',', 'Punctuation')\n",
      "('\"', 'Punctuation')\n",
      "('안심', 'Noun')\n",
      "('간단', 'Noun')\n",
      "('쾌적', 'Noun')\n",
      "('\"', 'Punctuation')\n",
      "('한', 'Verb')\n",
      "('디지털', 'Noun')\n",
      "('엔터테인먼트', 'Noun')\n",
      "('를', 'Josa')\n",
      "('제안', 'Noun')\n",
      "('하여', 'Verb')\n",
      "(',', 'Punctuation')\n",
      "('주요', 'Noun')\n",
      "('모델', 'Noun')\n",
      "('에', 'Josa')\n",
      "('대해', 'Noun')\n",
      "('다음', 'Noun')\n",
      "('과', 'Josa')\n",
      "('같이', 'Adverb')\n",
      "('기능', 'Noun')\n",
      "('강화', 'Noun')\n",
      "('를', 'Josa')\n",
      "('실시', 'Noun')\n",
      "('했다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('\\n\\n\\n', 'Foreign')\n",
      "('■', 'Foreign')\n",
      "('마치', 'Noun')\n",
      "('축제', 'Noun')\n",
      "('같은', 'Adjective')\n",
      "('출하', 'Noun')\n",
      "('식', 'Suffix')\n",
      "('!', 'Punctuation')\n",
      "('렛츠', 'Noun')\n",
      "('노트', 'Noun')\n",
      "('SX', 'Alpha')\n",
      "('1', 'Number')\n",
      "('출하', 'Noun')\n",
      "('시작', 'Noun')\n",
      "('\\n', 'Foreign')\n",
      "('2', 'Number')\n",
      "('월', 'Noun')\n",
      "('24', 'Number')\n",
      "('일', 'Noun')\n",
      "('에', 'Josa')\n",
      "('발매', 'Noun')\n",
      "('되는', 'Verb')\n",
      "('Let', 'Alpha')\n",
      "(\"'\", 'Punctuation')\n",
      "('snote', 'Alpha')\n",
      "('SX', 'Alpha')\n",
      "('1', 'Number')\n",
      "('/', 'Punctuation')\n",
      "('NX', 'Alpha')\n",
      "('1', 'Number')\n",
      "('의', 'Noun')\n",
      "('출하', 'Noun')\n",
      "('식이', 'Noun')\n",
      "('2', 'Number')\n",
      "('월', 'Noun')\n",
      "('8', 'Number')\n",
      "('일', 'Noun')\n",
      "('국내', 'Noun')\n",
      "('제조', 'Noun')\n",
      "('거점', 'Noun')\n",
      "('인', 'Josa')\n",
      "('고베', 'Noun')\n",
      "('공장', 'Noun')\n",
      "('에서', 'Josa')\n",
      "('열렸다', 'Verb')\n",
      "('.', 'Punctuation')\n",
      "('동사', 'Noun')\n",
      "('의', 'Josa')\n",
      "('컴퓨터', 'Noun')\n",
      "('로는', 'Josa')\n",
      "('처음', 'Noun')\n",
      "('실시', 'Noun')\n",
      "('하', 'Suffix')\n",
      "('는', 'Josa')\n",
      "('출하', 'Noun')\n",
      "('식', 'Suffix')\n",
      "('으로', 'Josa')\n",
      "(',', 'Punctuation')\n",
      "('이', 'Noun')\n",
      "('제품', 'Noun')\n",
      "('에', 'Josa')\n",
      "('얼마나', 'Noun')\n",
      "('힘', 'Noun')\n",
      "('이', 'Josa')\n",
      "('들어가', 'Verb')\n",
      "('있는지', 'Adjective')\n",
      "('알', 'Noun')\n",
      "('수', 'Noun')\n",
      "('있다', 'Adjective')\n",
      "('.', 'Punctuation')\n",
      "('\\n\\n\\n\\n', 'Foreign')\n",
      "('[', 'Punctuation')\n",
      "('엡손', 'Noun')\n",
      "('정품', 'Noun')\n",
      "('잉크', 'Noun')\n",
      "(']', 'Punctuation')\n",
      "('잉크', 'Noun')\n",
      "('카트리지', 'Noun')\n",
      "('6', 'Number')\n",
      "('색', 'Noun')\n",
      "('세트', 'Noun')\n",
      "('IC', 'Alpha')\n",
      "('6', 'Number')\n",
      "('CL', 'Alpha')\n",
      "('50', 'Number')\n",
      "('\\n', 'Foreign')\n",
      "('엡손', 'Noun')\n",
      "('\\n', 'Foreign')\n",
      "('출판사', 'Noun')\n",
      "(':', 'Punctuation')\n",
      "('Amazon.co.jp', 'URL')\n",
      "('\\n', 'Foreign')\n",
      "('입', 'Noun')\n",
      "('소문', 'Noun')\n",
      "('을', 'Josa')\n",
      "('본다', 'Verb')\n",
      "('\\n', 'Foreign')\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "for token in okt.pos(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Okt를 사용하려면 자바 1.7 이상이 필요함 (https://www.oracle.com/java/technologies/oracle-java-archive-downloads.html 의 JAVA SE13 다운로드)\n",
    "- 설치와 함께 환경변수(JAVA_HOME) 설정이 필요함\n",
    "- 자바 설치 및 환경변수 설정 후, https://www.lfd.uci.edu/~gohlke/pythonlibs/#jpype 를 통해 JPype 설치\n",
    "- JPype1-1.1.2-cp38-cp38-win_amd64.whl 로 진행하였음 (매우 중요 Python 3.8의 경우 버전 매칭이 까다로움)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 정규화\n",
    "- 앞서 추출한 형태소에서 분석에 불필요한 문자가 포함되어있는 것을 알 수 있음\n",
    "- 노이즈 제거가 필요함\n",
    "- 정규표현식(Regular Expression)을 사용해서 처리할 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      \n",
      "구형 에서 금단의 파워 업! 최신  나 소프트웨어를 한꺼번에 체크 [ 플래시백]\n",
      "텔레비전이나 와 연계 할 수있는  나 프로세서, 전환  등 재미있는 가 속속 등장했다 구형 의 금단이라고도 할 수있는 파워 업 방법에서 의 최신 , 화제의   , 새로운 보안 소프트웨어까지 한꺼번에 소개합니다\n",
      "\n",
      "■ 인텔  을 에 장착! 구형 은 얼마나 빨라질 것인가? (위)\n",
      "인텔이 최신  ' 시리즈'를 출시했다 현재  중에서도 최고의 성능을 자랑하는 이 제품을 구형 의 고속화를 도모한다는 점에서 리뷰 해 보았다 조금 색다른 리뷰가되지만, 어느 정도의 효과가 있는지, 기대가 크다\n",
      "\n",
      "\n",
      "■   \n",
      "  는 사용하는 가  (인텔   등)에서 으로 전환가능한 하이브리드 , 하지만 이와 동시에 도 바뀐다\n",
      "\n",
      "\n",
      "■ 초기 비용, 업데이트 비용 모두 무료! 저스트시스템, 도마뱀로그가 인상적인 보안 소프트웨어\n",
      "현재는 많은 사용자들이 에 보안 프로그램을 도입하고 있지만, 그 대부분은 매년 , 엔 정도 드는 업데이트 비용 과 그 절차에 대해 불만을 가지고있다 유료 소프트웨어를 이용하는 사용자의 약  %는 무료 보안 소프트웨어를 알고 있음에도 불구하고, 성능면에서 뒤 떨어지는 게 아니냐는 불안에서 도입을 미루고 있는 상황이다\n",
      "\n",
      "\n",
      "■ 텔레비전의 새로운 활용 방법을 제안! 의 봄 신상 는 와 를 연계\n",
      "는  년  월  일, 개인용 데스크톱  인 ' \"시리즈  종류  모델을  월  일부터 판매한다고 발표했다 신상품은 더 강력해진 녹화 기능 외에도  시청 · 녹화 기능에 더해서 업계 최초로 인기 를 연계한 ' 트위트 플러스'를 추가하는 등  컴퓨터 만의 기능을 탑재 스마트 폰 홈 네트워크 대응도 강화하고, \"안심 간단 쾌적\"한 디지털 엔터테인먼트를 제안하여, 주요 모델에 대해 다음과 같이 기능 강화를 실시했다\n",
      "\n",
      "\n",
      "■ 마치 축제같은 출하식! 렛츠 노트  출하 시작\n",
      " 월  일에 발매되는 '   의 출하식이  월  일 국내 제조 거점인 고베 공장에서 열렸다 동사의 컴퓨터로는 처음실시하는 출하식으로, 이 제품에 얼마나 힘이 들어가 있는지 알 수있다\n",
      "\n",
      "\n",
      "\n",
      "[엡손 정품 잉크] 잉크 카트리지  색 세트 \n",
      "엡손\n",
      "출판사  \n",
      "입소문을 본다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "reg_text = re.sub(r'[0-9a-zA-Z]+','', text)\n",
    "reg_text = re.sub(r'[:;/+\\.-]', '', reg_text)\n",
    "\n",
    "print(reg_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [0-9] : 숫자 0~9 중에 한 문자와 일치\n",
    "- [0-9a-z]+ : 숫자 0 ~ 9, 소문자 a ~ z 중에 한 문자 이상이 일치\n",
    "- 위의 조건을 통해 숫자와 알파벳이 삭제된 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어를 품사로 추출\n",
    "- 조사와 기호의 경우에는 그 자체로 의미가 없기에 데이터 셋에서 제거되는 경우가 있음\n",
    "- 자연어 처리 데이터 셋에는 주로 명사, 동사, 형용사인 단어가 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구형\n",
      "금단\n",
      "파워\n",
      "업\n",
      "최신\n",
      "나\n",
      "소프트웨어\n",
      "번\n",
      "체크\n",
      "플래시백\n",
      "텔레비전\n",
      "계\n",
      "수\n",
      "나\n",
      "프로세서\n",
      "전환\n",
      "등\n",
      "등장\n",
      "구형\n",
      "의\n",
      "금단\n",
      "수\n",
      "파워\n",
      "업\n",
      "방법\n",
      "의\n",
      "최신\n",
      "화제\n",
      "보안\n",
      "소프트웨어\n",
      "번\n",
      "소개\n",
      "인텔\n",
      "장착\n",
      "구형\n",
      "은\n",
      "얼마나\n",
      "것\n",
      "위\n",
      "인텔\n",
      "최신\n",
      "시리즈\n",
      "를\n",
      "출시\n",
      "현재\n",
      "중\n",
      "최고\n",
      "성능\n",
      "자랑\n",
      "이\n",
      "제품\n",
      "구형\n",
      "의\n",
      "고속\n",
      "도모\n",
      "점\n",
      "리뷰\n",
      "해\n",
      "조금\n",
      "리뷰\n",
      "정도\n",
      "효과\n",
      "기대\n",
      "사용\n",
      "인텔\n",
      "등\n",
      "전환\n",
      "하이브리드\n",
      "이\n",
      "동시\n",
      "도\n",
      "초기\n",
      "비용\n",
      "업데이트\n",
      "비용\n",
      "모두\n",
      "무료\n",
      "저스트\n",
      "시스템\n",
      "도마뱀\n",
      "로그\n",
      "인상\n",
      "보안\n",
      "소프트웨어\n",
      "현재\n",
      "사용자\n",
      "보안\n",
      "프로그램\n",
      "도입\n",
      "그\n",
      "대부분\n",
      "매년\n",
      "정도\n",
      "업데이트\n",
      "비용\n",
      "과\n",
      "그\n",
      "절차\n",
      "대해\n",
      "불만\n",
      "유료\n",
      "소프트웨어\n",
      "이용\n",
      "사용자\n",
      "약\n",
      "무료\n",
      "보안\n",
      "소프트웨어\n",
      "알\n",
      "불구\n",
      "성능\n",
      "면\n",
      "뒤\n",
      "게\n",
      "불안\n",
      "도입\n",
      "상황\n",
      "텔레비전\n",
      "활용\n",
      "방법\n",
      "제안\n",
      "의\n",
      "봄\n",
      "신상\n",
      "를\n",
      "계\n",
      "년\n",
      "월\n",
      "일\n",
      "개인\n",
      "용\n",
      "데스크톱\n",
      "인\n",
      "시리즈\n",
      "종류\n",
      "모델\n",
      "월\n",
      "일\n",
      "판매\n",
      "발표\n",
      "상품\n",
      "더\n",
      "녹화\n",
      "기능\n",
      "외\n",
      "시청\n",
      "녹화\n",
      "기능\n",
      "업계\n",
      "최초\n",
      "인기\n",
      "를\n",
      "계\n",
      "트\n",
      "위트\n",
      "플러스\n",
      "를\n",
      "추가\n",
      "등\n",
      "컴퓨터\n",
      "기능\n",
      "탑재\n",
      "스마트\n",
      "폰\n",
      "홈\n",
      "네트워크\n",
      "대응\n",
      "안심\n",
      "간단\n",
      "쾌적\n",
      "디지털\n",
      "엔터테인먼트\n",
      "제안\n",
      "주요\n",
      "모델\n",
      "대해\n",
      "다음\n",
      "기능\n",
      "강화\n",
      "실시\n",
      "마치\n",
      "축제\n",
      "출하\n",
      "렛츠\n",
      "노트\n",
      "출하\n",
      "시작\n",
      "월\n",
      "일\n",
      "발매\n",
      "의\n",
      "출하\n",
      "식이\n",
      "월\n",
      "일\n",
      "국내\n",
      "제조\n",
      "거점\n",
      "고베\n",
      "공장\n",
      "동사\n",
      "컴퓨터\n",
      "처음\n",
      "실시\n",
      "출하\n",
      "이\n",
      "제품\n",
      "얼마나\n",
      "힘\n",
      "알\n",
      "수\n",
      "엡손\n",
      "정품\n",
      "잉크\n",
      "잉크\n",
      "카트리지\n",
      "색\n",
      "세트\n",
      "엡손\n",
      "출판사\n",
      "입\n",
      "소문\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "for token in okt.nouns(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어느 정도 명사만 추출된 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 머신러닝을 위한 데이터 준비\n",
    "### 전체 기사의 형태소 분석\n",
    "- 전체 기사를 읽고 정규표현식을 적용한 다음 형태소 분석을 실시하고 명사인 단어를 추출하여 데이터 셋 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# 기사 폴더를 지정\n",
    "dirs = ['it-life-hack', 'movie-enter']\n",
    "\n",
    "# 단어와 레이블을 보존하는 리스트를 생성\n",
    "docterm = []     # 설명변수\n",
    "label = []       # 목적변수\n",
    "tmp1 = []\n",
    "tmp2 = ''\n",
    "\n",
    "# 각 폴더의 파일을 하나씩 읽어와서 표시\n",
    "for i, d in enumerate(dirs):\n",
    "    # 파일을 취득\n",
    "    files = os.listdir('./data/' + d)\n",
    "\n",
    "    # 파일을 오픈해서 내용을 취득\n",
    "    for file in files:\n",
    "        f = open('./data/' + d + '/' + file, 'r', encoding='utf-8')\n",
    "        text = f.read()\n",
    "\n",
    "        # 정규표현에서 불필요한 문자열을 제거해서 표시\n",
    "        reg_text = re.sub(r'[0-9a-zA-Z]+', '', text)\n",
    "        reg_text = re.sub(r'[:;/+\\.-]', '', reg_text)\n",
    "        reg_text = re.sub(r'[\\s\\n]', '', reg_text)\n",
    "\n",
    "        # 명사로 필터링된 형태소분석\n",
    "        for token in okt.nouns(reg_text):\n",
    "            tmp1.append(token)\n",
    "            tmp2 = ' '.join(tmp1)\n",
    "        # 기사별로 단어를 보존\n",
    "        docterm.append(tmp2)\n",
    "        tmp1 = []\n",
    "\n",
    "        # 기사별로 레이블을 붙여서 보존\n",
    "        label.append(i)\n",
    "        # 파일을 클로즈\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enumerate()를 통해 it-life_hack, movie-enter 폴더의 이미지 데이터를 인덱스로 붙여가며 읽음\n",
    "- tmp1, tmp2의 처리를 통해 기사별로 단어를 리스트 docterm에 추가\n",
    "- 기사별로 인덱스를 리스트 label에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구형 금단 파워 업 최신 소프트웨어 번 체크 플래시백 텔레비전 이나 계 프로세서 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>애플 개발자 미리보기 출시 차기 애플 년월 일 미국 캘리포니아주 쿠퍼티노 현지 시간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서비스 종료 후 전자책 디지털 통 컴퓨터 엔터테인먼트 휴대 용게 임기 전달 만화 콘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>웹페이지 이미지 통째 비결 이득 치트 시트 회사 소개 웹페이지 이미지 블로그 페이지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>레노버 프로 골퍼 사이토 선수 공식 후원 계약 체결 레노보 재팬 년월 프로 골퍼 사...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  구형 금단 파워 업 최신 소프트웨어 번 체크 플래시백 텔레비전 이나 계 프로세서 전...\n",
       "1  애플 개발자 미리보기 출시 차기 애플 년월 일 미국 캘리포니아주 쿠퍼티노 현지 시간...\n",
       "2  서비스 종료 후 전자책 디지털 통 컴퓨터 엔터테인먼트 휴대 용게 임기 전달 만화 콘...\n",
       "3  웹페이지 이미지 통째 비결 이득 치트 시트 회사 소개 웹페이지 이미지 블로그 페이지...\n",
       "4  레노버 프로 골퍼 사이토 선수 공식 후원 계약 체결 레노보 재팬 년월 프로 골퍼 사..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(docterm).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 통해 각 기사에 포함된 단어의 리스트를 확인할 수 있음\n",
    "- 한 행이 하나의 기사를 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구형 금단 파워 업 최신 소프트웨어 번 체크 플래시백 텔레비전 이나 계 프로세서 전환 등 등장 구형 금단 파워 업 방법 최신 화제 보안 소프트웨어 번 소개 인텔 장착 구형 얼마나 것 위 인텔 최신 시리즈 를 출시 현재 최고 성능 자랑 제품 구형 고속 도모 점 리뷰 조금 리뷰 정도 효과 대가 인텔 등 전환 하이브리드 만이 동시 초기 비용 업데이트 비용 무료 저스트 시스템 도마뱀 로그 인상 보안 소프트웨어 현재 사용자 보안 프로그램 도입 대부분 매년 정도 업데이트 비용 절차 대해 불만 가지 유료 소프트웨어 이용 사용자 의약 무료 보안 소프트웨어 불구 성능 면 뒤 불안 도입 상황 텔레비전 활용 방법 제안 의봄 신상 계 년월 일 데스크톱 시리즈 종류 모델 월일 판매 고 발표 상품 더 녹화 기능 외 시청 녹화 기능 업계 최초 인기 계 트 위트 플러스 를 추가 등 컴퓨터 기능 탑재 스마트폰 홈 네트워크 대응 안심 간단 쾌적 디지털 엔터테인먼트 제안 모델 대해 다음 기능 강화 실시 마치 축제 출하 렛츠 노트 출하 월일 발매 의 출하 이월 국내 거점 고베 공장 사의 컴퓨터 처음 실시 출하 제품 얼마나 힘 엡손 정품 잉크 잉크 카트리지 색 세트 엡손 출판사 입 소문\n"
     ]
    }
   ],
   "source": [
    "print(docterm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0행의 단어 리스트와 라벨링 결과를 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 문서 행렬의 작성\n",
    "- 형태소 분석에 의해 분할된 단어는 그 발생 횟수를 카운트해서 수치 데이터로 변환함\n",
    "- 일반적으로는 문서 중 포함된 각 단어의 출현 빈도를 Table 형식으로 가시화함\n",
    "- 이를 단어 문서 행렬이라고 부르며 세로 축에는 단어, 가로축에는 문서를 표시하는 행렬 형식으로 표현함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11125</th>\n",
       "      <th>11126</th>\n",
       "      <th>11127</th>\n",
       "      <th>11128</th>\n",
       "      <th>11129</th>\n",
       "      <th>11130</th>\n",
       "      <th>11131</th>\n",
       "      <th>11132</th>\n",
       "      <th>11133</th>\n",
       "      <th>11134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2      0      0      0      0      0      1      0      0      0      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   11125  11126  11127  11128  11129  11130  11131  11132  11133  11134  \n",
       "0      0      0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 11135 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "docterm_cv = cv.fit_transform(np.array(docterm))\n",
    "docterm_cnt = docterm_cv.toarray()\n",
    "\n",
    "pd.DataFrame(docterm_cnt).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 11135)\n",
      "['가가', '가가호호', '가각본', '가감', '가게', '가격', '가계', '가고시마', '가곡면', '가공', '가과', '가굉장', '가교', '가구', '가군', '가그에', '가극', '가극장', '가기', '가까이', '가끔', '가나', '가나가와현', '가나타', '가내', '가년', '가능', '가능성', '가다해', '가담', '가대', '가도', '가동', '가두', '가드', '가득', '가든', '가디스', '가라', '가라데', '가라오케', '가라테', '가랑이', '가량', '가렛', '가로', '가로막', '가로세로', '가로축', '가르시아']\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(docterm_cnt).shape)\n",
    "print(cv.get_feature_names()[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>영화</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>사람</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>생각</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>작품</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>때문</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "6393  영화  746\n",
       "4398  사람  612\n",
       "4674  생각  610\n",
       "7830  작품  578\n",
       "2408  때문  409"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcnt = []\n",
    "\n",
    "docterm_wcnt = np.sum(a=docterm_cnt, axis=0)\n",
    "for w, cnt in zip(cv.get_feature_names(), docterm_wcnt):\n",
    "    wcnt.append([w, cnt])\n",
    "\n",
    "wcnt_df = pd.DataFrame(wcnt)\n",
    "wcnt_df = wcnt_df.sort_values(1, ascending=False)\n",
    "wcnt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 통해 고빈도어를 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11125</th>\n",
       "      <th>11126</th>\n",
       "      <th>11127</th>\n",
       "      <th>11128</th>\n",
       "      <th>11129</th>\n",
       "      <th>11130</th>\n",
       "      <th>11131</th>\n",
       "      <th>11132</th>\n",
       "      <th>11133</th>\n",
       "      <th>11134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2      0      0      0      0      0      1      0      0      0      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   11125  11126  11127  11128  11129  11130  11131  11132  11133  11134  \n",
       "0      0      0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 11135 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0.01, max_df=0.5)\n",
    "docterm_cv = cv.fit_transform(np.array(docterm))\n",
    "dcterm_cnt = docterm_cv.toarray()\n",
    "\n",
    "pd.DataFrame(docterm_cnt).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>정기</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>등각</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>공식</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>절규</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>정점</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "2408  정기  409\n",
       "698   등각  369\n",
       "234   공식  321\n",
       "2387  절규  268\n",
       "2422  정점  250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcnt = []\n",
    "\n",
    "docterm_wcnt = np.sum(a=docterm_cnt, axis=0)\n",
    "for w, cnt in zip(cv.get_feature_names(), docterm_wcnt):\n",
    "    wcnt.append([w, cnt])\n",
    "\n",
    "wcnt_df = pd.DataFrame(wcnt)\n",
    "wcnt_df = wcnt_df.sort_values(1, ascending=False)\n",
    "wcnt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고빈도어와 저빈도어를 삭제하였으며, 결과를 통해 확인이 가능함\n",
    "- min_df는 하한선, max_df는 상한선을 정의한 파라미터임  \n",
    "\n",
    "### TF-IDF에 의한 가중치 설정\n",
    "- 단어의 발생횟수만으로는 고효율의 특징량을 추출할 수 없음\n",
    "- 따라서 단어 문서 행렬에서는 단어의 출현빈도(TF, Term Frequency)에 역문서빈도 (IDF, Inverse Document Frequency)를 곱한 TF-IDF치를 활용함\n",
    "- IDF치는 log(총문서수/(특정 단어가 출현하는 문서수))+1 임\n",
    "- 특정 문서에만 출현하는 단어일수록 IDF 값이 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3209</th>\n",
       "      <th>3210</th>\n",
       "      <th>3211</th>\n",
       "      <th>3212</th>\n",
       "      <th>3213</th>\n",
       "      <th>3214</th>\n",
       "      <th>3215</th>\n",
       "      <th>3216</th>\n",
       "      <th>3217</th>\n",
       "      <th>3218</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2     3     4     5     6     7         8     9     ...  \\\n",
       "0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...   \n",
       "1   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...   \n",
       "2   0.0   0.0  0.050981   0.0   0.0   0.0   0.0   0.0  0.095754   0.0  ...   \n",
       "3   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...   \n",
       "4   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...   \n",
       "\n",
       "       3209  3210  3211  3212  3213  3214  3215  3216  3217  3218  \n",
       "0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  0.090289   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3219 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df = 0.01, max_df = 0.5, sublinear_tf = True)\n",
    "docterm_tv = tv.fit_transform(np.array(docterm))\n",
    "docterm_tfidf = docterm_tv.toarray()\n",
    "\n",
    "pd.DataFrame(docterm_tfidf).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3219)\n",
      "['가가', '가게', '가격', '가공', '가기', '가까이', '가끔', '가나', '가년', '가능', '가능성', '가담', '가도', '가득', '가라데', '가로', '가로막', '가면', '가면라이더', '가모', '가발', '가방', '가브리엘', '가사', '가상', '가속', '가수', '가슴', '가시', '가신', '가약', '가연', '가온', '가요', '가운데', '가위', '가을', '가의', '가이드', '가일', '가입', '가장', '가전', '가정', '가족', '가주', '가지', '가집', '가짜', '가차', '가출', '가치', '가파도', '각각', '각국', '각도', '각본', '각의', '각종', '각지', '간다', '간단', '간호사', '갈등', '갈수', '감각', '감격', '감금', '감독', '감동', '감사', '감상', '감수', '감시', '감염', '감정', '감지', '갑자기', '강도', '강요', '강제', '강조', '강타', '강화', '개구리', '개국', '개그', '개념', '개막', '개발', '개발자', '개방', '개별', '개봉', '개사', '개선', '개성', '개시', '개요', '개월', '개인', '개정', '개최', '개혁', '객관', '객석', '갤러리', '거기', '거나', '거대', '거듭', '거래', '거리', '거물', '거실', '거울', '거의', '거절', '거점', '거주', '거지', '거짓말', '거편', '걱정', '건강', '건너', '건담', '건물', '건축', '걸작', '검사', '검색', '검술', '검증', '검토', '게다', '게다가', '게살', '게스트', '게시', '게이', '게일', '게임', '게임기', '게재', '게키', '겨냥', '겨우', '겨울', '격동', '격투', '격투기', '결과', '결론', '결말', '결사', '결성', '결심', '결연', '결의', '결전', '결정', '결집', '결코', '결합', '결혼', '겸비', '경계', '경고', '경과', '경기', '경량', '경력', '경로', '경연', '경우', '경위', '경의', '경쟁', '경지', '경찰', '경향', '경험', '계기', '계산', '계속', '계약', '계정', '계획', '고가', '고객', '고교생', '고급', '고대', '고도', '고등학교', '고려', '고립', '고립무원', '고민', '고백', '고비', '고생', '고성능', '고속', '고스트', '고양이', '고영상', '고요', '고용', '고유', '고이', '고자', '고장', '고정', '고조', '고지', '고집', '고통', '고하', '고해', '고향', '고화질', '곡예', '곳곳', '곳도', '공간', '공감', '공개', '공격', '공급', '공기', '공동', '공부', '공식', '공연', '공연장', '공유', '공작', '공장', '공중', '공통', '공통점', '공포', '공포영화', '공포증', '과거', '과시', '과연', '과정', '관객', '관객수', '관건', '관계', '관계자', '관광명소', '관련', '관리', '관리자', '관민', '관심', '관여', '관점', '관해', '광고', '광구', '광선검', '광야', '괴도', '괴물', '교도소', '교류', '교사', '교섭', '교수', '교육', '교차', '교체', '교환', '구가', '구글', '구나', '구도', '구동', '구리', '구매', '구멍', '구분', '구사', '구상', '구성', '구의', '구입', '구제', '구조', '구체', '구축', '구치', '구현', '구형', '국가', '국경', '국내', '국민', '국제', '국채', '군인', '굴지', '궁극', '궁리', '궁박', '궁지', '궁합', '권력', '규격', '규모', '규칙', '그것', '그냥', '그녀', '그늘', '그다지', '그대로', '그동안', '그때', '그랑프리', '그래픽', '그래픽카드', '그레이', '그룹', '그리스', '그리피스', '그린', '그린랜턴', '그림', '그림자', '그물', '극복', '극작가', '극장', '극장판', '극적', '극찬', '극한', '근거', '근무', '근성', '근육', '근처', '글로리아', '글로벌', '금괴', '금단', '금도', '금속', '금은', '금지', '금화', '기간', '기계', '기관', '기구', '기기', '기념', '기능', '기대', '기도', '기동전', '기록', '기반', '기법', '기본', '기분', '기쁨', '기사', '기상', '기색', '기세', '기소', '기술', '기억', '기업', '기용', '기운', '기원', '기자', '기자회견', '기적', '기전', '기존', '기준', '기초', '기타', '기한', '기호', '기회', '기획', '긴급', '긴자', '긴장', '긴장감', '길이', '깊이', '까운', '깜짝', '꽃다발', '꽃미남', '끼리', '나가노', '나기', '나나', '나날', '나라', '나름', '나마', '나머지', '나미', '나사', '나오미', '나이', '나중', '나카가와', '나카무라', '낙하', '난사람', '날개', '날씨', '날짜', '남극', '남녀', '남성', '남아', '남우', '남자', '남자친구', '남편', '납득', '납치', '낭비', '내년', '내면', '내부', '내용', '내의', '내장', '냄새', '냉각', '네트워크', '넥스트', '녀석', '년대', '년도', '년월', '년전', '년판', '년후', '노래', '노력', '노리', '노미네이트', '노부', '노시', '노출', '노키', '노트', '노트북', '녹색', '녹화', '놀이', '농담', '농락', '높이', '누구', '누군가', '누뿌', '누수', '눈길', '눈물', '눈앞', '눈치', '뉴스', '뉴욕', '느낌', '는가', '는고', '는바', '능력', '능화', '니시', '니코', '닐캬', '다각', '다그', '다기', '다나', '다나카', '다년', '다누', '다니엘', '다단', '다대', '다른', '다른사람', '다리', '다마', '다만', '다모', '다미', '다방면', '다분', '다비', '다빈치', '다사', '다소', '다수', '다스', '다시', '다양', '다예', '다오', '다용', '다운로드', '다음', '다음주', '다중', '다카', '다큐멘터리', '다크', '다합', '다해', '다행', '다화', '단계', '단말', '단말기', '단번', '단상', '단순', '단어', '단언', '단연', '단위', '단자', '단장', '단지', '단체', '단추', '단편화', '달라', '달러', '달리', '달인', '달타냥', '담당', '담당자', '답습', '당시', '당신', '당일', '당초', '당황', '대가', '대결', '대기', '대기업', '대답', '대략', '대량', '대로', '대망', '대면', '대본', '대부분', '대비', '대사', '대상', '대신', '대여', '대역', '대은', '대응', '대의', '대작', '대전', '대지진', '대책', '대처', '대체', '대치', '대통령', '대폭', '대표', '대하', '대학', '대한', '대해', '대형', '대화', '대화면', '대회', '댄스', '댓글', '더링', '더보', '더빙', '더시티', '더욱', '덕분', '데리', '데뷔', '데스크탑', '데스크톱', '데스티네이션', '데이', '데이먼', '데이비드', '데이타', '데이터', '데이트', '도구', '도구모음', '도나', '도달', '도대체', '도도', '도등', '도라에몽', '도로', '도록', '도망', '도모', '도부', '도사', '도서', '도시', '도심', '도약', '도움', '도의', '도일', '도입', '도전', '도중', '도지원', '도착', '도코모', '도쿄', '도쿄도', '도키', '도피', '도하', '독립', '독립영화', '독서', '독일', '독자', '독점', '돌입', '돌진', '돌출', '돌파', '돕기', '동경', '동급생', '동기화', '동등', '동료', '동명', '동물', '동생', '동성애', '동시', '동안', '동영상', '동원', '동일본', '동작', '동하', '동행', '동향', '동화', '두께', '두뇌', '두려움', '두번째', '두운', '둘이서', '뒤마', '듀스', '듀얼', '듀얼코어', '드라마', '드라이버', '드라이브', '드래곤', '드레스', '드림', '듬뿍', '등각', '등국', '등단', '등록', '등세', '등수', '등자', '등장', '등장인물', '등지', '등호', '디럭스', '디스크', '디스플레이', '디어', '디자인', '디즈니', '디지털', '디지털카메라', '디카프리오', '디케이', '따라서', '따위', '딱따구리', '때로는', '때문', '때앱', '또한', '뜻밖', '라든지', '라디오', '라며', '라면', '라미', '라보', '라스', '라우터', '라이', '라이벌', '라이브', '라이터', '라이트', '라이프', '라인', '라인업', '래그', '래빗', '래서', '랭킹', '러먼', '러브', '러브스토리', '러셀', '런던', '레그', '레노버', '레노보', '레드', '레드카펫', '레디', '레벨', '레비', '레오나르도', '레이', '레이저', '레인지', '레코', '렌탈', '렛츠', '려고', '려면', '로건', '로고', '로그', '로그인', '로드', '로만', '로맨스', '로미', '로버트', '로봇', '로부터', '로사', '로서', '로스', '로스앤젤레스', '로우', '로이', '로저스', '롤러코스터', '롯폰기', '롯폰기힐즈', '루블', '루시', '루즈', '류헤이', '리더', '리드', '리모콘', '리뷰', '리사', '리순', '리스', '리스트', '리암', '리얼', '리얼리티', '리얼스틸', '리외', '리지', '리코', '린다', '릴리', '링크', '마감', '마구', '마더', '마더보드', '마련', '마루', '마루노우치', '마리', '마무리', '마미', '마법', '마부', '마사', '마사토', '마스', '마스크', '마스터', '마쓰', '마오', '마우스', '마을', '마음', '마음껏', '마음대로', '마이', '마이스', '마이크', '마이크로소프트', '마이클', '마이티', '마인드', '마자', '마주', '마지막', '마찬가지', '마츠', '마츠다류헤이', '마츠모토', '마치', '마침내', '마카', '마크', '마키', '마하', '막대', '막스', '만끽', '만난', '만남', '만대', '만들기', '만사', '만약', '만엔', '만원', '만일', '만조', '만족', '만큼', '만화', '말레이시아', '말로', '말씀', '망상', '맞이', '맞춤', '매기', '매듭', '매력', '매료', '매번', '매우', '매일', '매입', '매장', '매출', '맥스', '맥주', '머니볼', '머리', '머리카락', '먼저', '멀티', '메가폰', '메뉴', '메모', '메모리', '메모리카드', '메시지', '메이커', '메이크업', '메이킹', '메인', '메인보드', '메일', '메타', '멤버', '면서', '면알', '명령', '명소', '명예', '명의', '명작', '명장', '명중', '명콤비', '몇개', '몇번', '모건', '모노', '모니터', '모델', '모두', '모드', '모든', '모리', '모모', '모모이로', '모바일', '모방', '모습', '모양', '모집', '모처럼', '모카', '모타', '모테키', '모토', '모티브', '모험', '목걸이', '목격', '목록', '목마', '목소리', '목숨', '목적', '목적지', '목표', '몬스터', '몰래', '몰입', '몹시', '묘사', '무게', '무기', '무늬', '무니', '무대', '무려', '무렵', '무료', '무리', '무상', '무선', '무슨', '무심코', '무언가', '무엇', '무용', '무제한', '무척', '무토', '묶음', '문고', '문서', '문신', '문의', '문자', '문장', '문제', '문제해결', '문화', '물건', '물리', '물의', '뭔가', '뮤지션', '미가', '미국', '미국만화', '미나미', '미녀', '미니', '미닛', '미디어', '미라', '미래', '미리', '미리보기', '미션', '미션임파서블', '미소', '미소녀', '미술품', '미스', '미씨', '미아', '미야자키', '미요', '미요시', '미우라', '미유키', '미조', '미지', '미치광이', '미카', '미코', '미키', '미타', '밀리', '밀착', '바다', '바닥', '바디', '바란', '바람', '바로', '바보', '바스', '바이러스', '바이오해저드', '바이트', '바타', '바탕', '바탕화면', '박력', '박물관', '박사', '박수', '박자', '반대', '반드시', '반론', '반면', '반복', '반생', '반영', '반응', '반의', '반지', '발견', '발굴', '발길', '발렌타인', '발렌타인데이', '발매', '발상', '발생', '발신', '발언', '발음', '발자취', '발전', '발칵', '발탁', '발트', '발표', '발표회', '발휘', '방문', '방법', '방송', '방수', '방식', '방어', '방지', '방치', '방침', '방해', '방향', '방화', '배경', '배달', '배신', '배역', '배우', '배우진', '배짱', '배치', '배터리', '배포', '백과사전', '백만장자', '백신', '백업', '밴드', '뱀파이어', '뱀파이어헌터', '뱅크', '버스', '버전', '버진', '버크', '버킹엄', '버튼', '버팔로', '번만', '번역', '번영', '번은', '번의', '번호', '범위', '범인', '범죄', '범죄자', '범행', '법률', '법칙', '베네치아', '베니스', '베니스영화제', '베르세르크', '베를린', '베스트셀러', '변경', '변신', '변호', '변호사', '변화', '변환', '별도', '별로', '병동', '병사', '병행', '보가', '보고', '보고서', '보급', '보기', '보도', '보드', '보머', '보물', '보상', '보안', '보유', '보이', '보이지', '보장', '보증', '보지', '보컬', '보통', '보호', '복구', '복귀', '복사', '복수', '복습', '본격', '본능', '본래', '본명', '본사', '본인', '본적', '본조비', '본질', '본체', '볼거리', '볼때', '볼륨', '봉인', '부가', '부과', '부담', '부도', '부동산', '부루', '부모', '부문', '부부', '부분', '부상', '부속품', '부스', '부업', '부여', '부응', '부인', '부자', '부작', '부적', '부정', '부족', '부착', '부탁', '부터', '부팅', '부품', '부하', '부활', '부흥', '북마크', '북미', '분과', '분기', '분노', '분리', '분명', '분산', '분석', '분야', '분위기', '불가사의', '불과', '불구', '불륜', '불만', '불명', '불발', '불법', '불안', '불편', '붕괴', '붙이', '브라우저', '브라이언', '브래드피트', '브랜드', '브레이크', '블랙', '블로그', '블록', '블록버스터', '블루', '블루레이', '블룸', '비결', '비교', '비극', '비등', '비디오', '비롯', '비밀', '비밀번호', '비법', '비비', '비용', '비율', '비장', '비조', '비주', '비즈니스', '비치', '비트', '비행', '비행기', '비행선', '비화', '빈손', '빛과', '뿌리', '사가', '사각', '사건', '사고', '사과', '사관', '사기', '사나이', '사냥', '사라', '사람과', '사랑', '사례', '사망', '사무', '사무소', '사상', '사생활', '사실', '사야카', '사양', '사업', '사용', '사용자', '사운드', '사의', '사이', '사이버', '사이버범죄', '사이즈', '사이토', '사이트', '사인', '사장', '사적', '사전', '사정', '사진', '사진작가', '사진전', '사진촬영', '사체', '사카', '사카모토', '사쿠라', '사키', '사태', '사토', '사투', '사항', '사회', '삭제', '산업', '살인', '살인마', '살해', '삼삼칠', '삼총사', '상경', '상공', '상기', '상단', '상대', '상대로', '상드', '상등', '상륙', '상상', '상상력', '상세', '상승', '상식', '상실', '상영', '상위', '상의', '상이', '상자', '상적', '상징', '상처', '상태', '상품', '상하', '상황', '색상', '샐러리맨', '샘플', '생각', '생략', '생명', '생물', '생산', '생업', '생일', '생해', '생활', '샤아', '서나', '서도', '서로', '서류', '서버', '서부', '서비스', '서서히', '서스펜스', '서재', '서쪽', '선공', '선구자', '선두', '선물', '선배', '선생님', '선수', '선언', '선전', '선정', '선착순', '선출', '선택', '선행', '설계', '설득', '설리반', '설립', '설마', '설명', '설정', '설치', '성격', '성공', '성과', '성능', '성룡', '성미', '성우', '성원', '성인', '성장', '성적', '세계', '세계관', '세계대전', '세금', '세기', '세대', '세로', '세번', '세부', '세상', '세션', '세월', '세트', '섹스', '섹시', '센서', '센터', '센티미터', '셜록홈즈', '소가', '소감', '소개', '소녀', '소년', '소니', '소니에릭슨', '소리', '소림축구', '소문', '소비', '소비자', '소비전력', '소설', '소셜', '소셜게임', '소속', '소스', '소식', '소위', '소유', '소재', '소품', '소프트', '소프트뱅크', '소프트웨어', '소형', '속도', '속성', '속편', '손가락', '손님', '손상', '손실', '손씨', '손자', '손정', '손질', '솔루션', '솔저', '쇼월일', '쇼코', '쇼타', '쇼핑', '수가', '수감', '수단', '수동', '수량', '수록', '수명', '수법', '수사', '수상', '수상자', '수상작', '수상한', '수수께끼', '수여', '수용', '수의', '수익', '수정', '수준', '수직', '수행', '숙적', '순간', '순식간', '순위', '순차', '숨기', '숫자', '슈퍼', '슈퍼마리오', '슈퍼영웅', '스릴', '스마일', '스마트', '스마트폰', '스스로', '스위치', '스즈키', '스카', '스카이라인', '스칼라', '스캔', '스컬', '스케', '스케일', '스콧', '스크린', '스크림', '스타', '스타워즈', '스타일', '스타트', '스태프', '스탠드', '스탭', '스턴', '스테레오', '스테이', '스테이지', '스토리', '스토어', '스톤', '스튜디오', '스트랩', '스트레스', '스트리밍', '스트리트', '스티브', '스티븐', '스틸', '스파이', '스파이더맨', '스팟', '스페셜', '스페인', '스펙', '스프레드', '스피드', '스피커', '스필버그', '슬롯', '슬림', '슬픔', '습격', '습도', '승리', '승부', '승자', '시가', '시각', '시간', '시계', '시기', '시나', '시네마', '시대', '시도', '시로', '시리즈', '시마', '시미즈', '시바', '시보', '시부야', '시사회', '시상식', '시선', '시설', '시스루', '시스템', '시오', '시작', '시장', '시절', '시점', '시즌', '시청', '시청률', '시청자', '시카고', '시큐리티', '시트', '시험', '식사', '신경', '신곡', '신규', '신념', '신데렐라', '신도', '신들', '신뢰', '신문', '신비', '신의', '신인', '신작', '신제품', '신주쿠', '신청', '신체', '신판', '신형', '실감', '실기', '실력', '실버', '실사', '실사영화', '실세', '실수', '실시', '실시간', '실적', '실전', '실제', '실종', '실패', '실행', '실험', '실현', '실화', '심리', '심사', '심장', '심정', '심플', '십년', '십자가', '싱글', '싸움', '쓰기', '쓰레기', '쓰리데이즈', '아가씨', '아군', '아내', '아들', '아래', '아레나', '아론', '아마', '아무', '아바타', '아버지', '아베', '아빠', '아스', '아시아', '아야', '아역', '아오이', '아이', '아이돌', '아이디어', '아이언맨', '아이오', '아이콘', '아이템', '아저씨', '아주', '아침', '아카데미', '아카데미상', '아키', '아키라', '아키바', '아키코', '아키하바라', '아티스트', '아파트', '악곡', '악녀', '악당', '악마', '악몽', '악성', '악성코드', '악역', '악용', '악의', '안경', '안고', '안내', '안녕', '안성맞춤', '안심', '안전', '안정', '안토니오', '안톤', '알렉', '알림', '암살', '암살자', '암호', '압도', '압력', '압축', '앞서', '애국심', '애니메이션', '애니메이션영화', '애프터', '애플', '애플리케이션', '액세스', '액션', '액션영화', '액정', '앤더슨', '앨범', '앰버', '야마', '야마다', '야스', '야심', '야외', '약간', '약속', '약자', '약점', '양론', '양립', '양면', '양식', '얘기', '어깨', '어댑터', '어둠', '어디', '어디가', '어딘가', '어려움', '어로', '어른', '어린시절', '어머니', '어명', '어스', '어제', '어쨌든', '어쩌면', '어플', '어플리케이션', '어필', '어회', '언급', '언론', '언어', '언제', '얼굴', '얼마', '얼마나', '얼짱', '엄마', '엄선', '업계', '업그레이드', '업데이트', '업로드', '업무', '업체', '엉덩이', '에나', '에너지', '에두', '에드', '에드가', '에디', '에리', '에릭', '에밀리', '에바', '에스', '에이', '에이리언', '에이번', '에이전트', '에일', '에전', '에지', '에프', '에피소드', '엔진', '엔터', '엔터테인먼트', '엘리', '엘리자베스', '엘리트', '엡손', '여고생', '여기', '여대생', '여러', '여러가지', '여러분', '여름', '여배우', '여백', '여부', '여성', '여신', '여우주연상', '여유', '여자', '여장', '여주', '여지', '여행', '역대', '역사', '역시', '역전', '역할', '연결', '연관', '연구', '연구소', '연기', '연상', '연속', '연수', '연습', '연애', '연애영화', '연예계', '연예인', '연인', '연재', '연주', '연출', '연한', '열광', '열기', '열대어', '열람', '열쇠', '열연', '열정', '열중', '영감', '영광', '영국', '영문', '영상', '영어', '영업', '영역', '영웅', '영향', '영혼', '영화', '영화감독', '영화계', '영화관', '영화동', '영화로', '영화리뷰', '영화비평', '영화사', '영화제', '영화제작', '예감', '예견', '예고', '예고편', '예매', '예산', '예상', '예술', '예의', '예전', '예정', '예측', '옛날', '오구', '오늘', '오늘아침', '오니', '오디션', '오디오', '오른쪽', '오리', '오버', '오버클럭', '오브', '오사카', '오스', '오스카', '오스트리아', '오오', '오오시마', '오오이', '오지', '오카', '오카모토', '오키나와', '오프닝', '오픈', '오히려', '온도', '온라인', '올랜도', '올해', '옵션', '옷장', '와우', '와인', '와일드', '와코', '와콤', '와타나베', '완결', '완료', '완벽', '완성', '완수', '완전', '왓쇼', '왓슨', '왕국', '왕비', '왜곡', '외계인', '외국인', '외로', '외모', '외부', '외출', '외형', '왼쪽', '요괴', '요구', '요금', '요나', '요리', '요보', '요소', '요시', '요시카', '요염', '요원', '요인', '요청', '요코', '요하', '욕망', '욕심', '용기', '용도', '용량', '용법', '용병', '용의', '용이', '용한', '용해', '우드', '우등', '우리', '우메다', '우선', '우정', '우주', '우치', '운동', '운명', '운영', '울트라', '울트라북', '움직임', '웃음', '워드', '원래', '원빈', '원숭이', '원외', '원인', '원작', '원점', '원제', '월간', '월드', '월일', '월트디즈니', '웹페이지', '위기', '위로', '위원', '위젯', '위치', '위해', '위험', '위협', '윌리', '유기', '유닛', '유대', '유라', '유래', '유럽', '유력', '유료', '유리', '유머', '유명', '유명인사', '유산', '유선', '유스케', '유우', '유원지', '유의', '유저', '유지', '유키', '유키나', '유틸리티', '유형', '육박', '육체', '융합', '은둔', '은미', '은별', '은사', '은세계', '은월', '은제', '은주', '은지원', '은하', '을기', '을사', '을소', '을시', '을제', '을지', '을해', '음모', '음성', '음성인식', '음식', '음악', '응답', '응모', '응용', '응용프로그램', '응원', '응축', '의개', '의거', '의견', '의결', '의경', '의과', '의기', '의기사', '의대', '의도', '의무', '의문', '의미', '의분', '의비', '의사', '의상', '의성', '의소', '의수', '의식', '의심', '의아', '의약', '의역', '의연', '의외', '의용', '의원', '의의', '의인', '의장', '의전', '의제', '의존', '의주', '의중', '의지', '의타', '이강', '이개', '이결', '이굉', '이군', '이그', '이기', '이나', '이단', '이동', '이드', '이득', '이란', '이론', '이름', '이마', '이메일', '이면', '이모', '이몸', '이미지', '이번', '이벤트', '이별', '이보', '이본', '이부', '이비', '이빛나', '이사', '이상', '이색', '이세', '이수', '이스', '이스트', '이아', '이안', '이야기', '이여기', '이역', '이영화', '이외', '이용', '이월', '이유', '이이', '이익', '이인기', '이일', '이자', '이자연', '이적', '이전', '이점', '이제', '이주', '이주연', '이즈미', '이지연', '이진행', '이치', '이케다', '이크', '이탈리아', '이토', '이하', '이해', '이혼', '이활', '이후', '인간', '인간관계', '인공', '인구', '인기', '인류', '인류사', '인물', '인사', '인상', '인생', '인생역전', '인세', '인쇄', '인식', '인연', '인용', '인의', '인재', '인정', '인조', '인증', '인지', '인치', '인터넷', '인터뷰', '인터페이스', '인텔', '인형', '일간', '일괄', '일단', '일대', '일도', '일동', '일라이', '일러스트', '일로', '일리', '일만', '일면', '일반', '일반인', '일본', '일본어', '일본인', '일부', '일부러', '일상', '일상생활', '일시', '일어난다', '일이', '일일이', '일자', '일전', '일정', '일제', '일주일', '일지', '일체', '일행', '임무', '입력', '입사', '입수', '입장', '입장료', '입체', '잉크', '자극', '자금', '자기', '자녀', '자동', '자동차', '자등', '자랑', '자료', '자리', '자명', '자미', '자본', '자부', '자사', '자세', '자식', '자신', '자신감', '자아', '자연', '자영', '자유', '자의', '자작', '자전거', '자정', '자주', '자중', '자책', '자체', '자칭', '자키', '자하', '작가', '작고', '작년', '작동', '작성', '작업', '작업표시줄', '작전', '작품', '잔량', '잘못', '잠깐', '잠입', '잡지', '장공', '장관', '장기', '장난', '장내', '장단점', '장대', '장독', '장렬', '장르', '장만', '장면', '장비', '장성', '장소', '장시간', '장식', '장유', '장의', '장점', '장착', '장치', '장편', '장하', '장형', '재기', '재능', '재료', '재미', '재산', '재생', '재치', '재키', '재판', '재팬', '재현', '재회', '잭스', '잭슨', '저스틴팀버레이크', '저자', '저장', '저하', '저항', '적극', '적외선', '적의', '전개', '전개도', '전국', '전날', '전달', '전당', '전략', '전력', '전례', '전망', '전면', '전문', '전문가', '전반', '전사', '전설', '전세계', '전송', '전송속도', '전수', '전시', '전시회', '전압', '전용', '전원', '전의', '전이', '전자', '전자책', '전작', '전장', '전쟁', '전제', '전직', '전체', '전통', '전투', '전파', '전편', '전하', '전해', '전혀', '전화', '전환', '전회', '전후', '절규', '절대', '절대로', '절도', '절실', '절약', '절전', '절정', '절차', '절찬', '절호', '젊은이', '점수', '점유', '점점', '점차', '점프', '접근', '접속', '접수', '정규', '정기', '정도', '정리', '정말', '정보', '정복', '정부', '정성', '정식', '정신', '정은', '정의', '정의감', '정이', '정점', '정지', '정착', '정체', '정품', '제거', '제곱', '제공', '제네시스', '제대로', '제도', '제드', '제로', '제목', '제시카', '제안', '제어', '제외', '제의', '제이슨', '제일', '제임스', '제작', '제작비', '제작자', '제조', '제조업체', '제출', '제품', '제한', '제화', '제회', '제휴', '조각', '조건', '조교', '조금', '조명', '조사', '조속', '조언', '조작', '조절', '조정', '조지', '조직', '조치', '조합', '존경', '존스', '존재', '졸업', '좀더', '좀처럼', '종래', '종료', '종류', '종사', '종이', '종이접기', '종합', '종횡무진', '좌우', '좌절', '주년', '주류', '주리', '주말', '주목', '주문', '주변', '주사', '주소', '주식회사', '주얼', '주역', '주연', '주요', '주위', '주의', '주인', '주인공', '주일', '주제', '주제가', '주최', '주파수', '죽음', '준비', '줄거리', '줄리아', '중간', '중국', '중국인', '중반', '중순', '중심', '중요성', '중인', '중지', '중하', '중학교', '즉시', '즐거움', '즐겨찾기', '증가', '증거', '증명', '증정', '지고', '지구', '지금', '지난', '지난주', '지난해', '지능', '지도', '지도자', '지면', '지배', '지불', '지상', '지상파', '지속', '지시', '지식', '지역', '지원', '지위', '지적', '지정', '지지', '지진', '지하', '지하철', '지향', '지혜', '지휘', '직관', '직면', '직업', '직원', '직장', '직전', '직접', '직후', '진공', '진상', '진실', '진심', '진의', '진입', '진짜', '진출', '진행', '진화', '질감', '질리', '질문', '질의', '질주', '집결', '집기', '집단', '집의', '집중', '집착', '집필', '집합', '징계', '짹짹', '차기', '차량', '차례', '차례차례', '차림', '차세대', '차이', '차지', '차트', '차파', '착각', '착용', '찬스', '찰리', '참가', '참고', '참석', '참여', '참조', '창세기', '채널', '채용', '채택', '책임', '챔피언', '처럼', '처리', '처음', '천엔', '천외', '천재', '철저', '철학', '첨부', '첫경험', '첫날', '첫등장', '청구', '청년', '청춘', '체감', '체결', '체크', '체포', '체험', '초고', '초과', '초기', '초대', '초보자', '초월', '초인', '초점', '초청', '총명', '총알', '촬영', '촬영현장', '최강', '최고', '최고급', '최근', '최대', '최대한', '최소', '최소한', '최신', '최악', '최우수', '최적', '최적화', '최종', '최종회', '최초', '추가', '추구', '추억', '추적', '추정', '추천', '추첨', '추측', '축소', '축제', '축하', '출력', '출발', '출시', '출신', '출연', '출연자', '출장', '출전', '출판', '출판사', '출품', '출하', '출현', '충격', '충실', '충전', '충전기', '충족', '취급', '취득', '취소', '취임', '취재', '취하', '취향', '츠바키', '츠시마', '츠키', '측정', '치가', '치료', '치카', '치코', '치트', '친구', '친필', '침략', '침묵', '침실', '침투', '칭찬', '카가와', '카드', '카디', '카리', '카리스마', '카메라', '카메론', '카시', '카오루', '카우보이', '카이', '카이지', '카츠', '카테고리', '카토', '카트리지', '카펫', '칵테일', '칼럼', '캐논', '캐릭터', '캐스트', '캐스팅', '캐시', '캘리포니아', '캠페인', '캡처', '캡틴아메리카', '커넥터', '커뮤니케이션', '커뮤니티', '커버', '커플', '컨드', '컨텐츠', '컨트롤', '컨트롤러', '컬러', '컬렉터', '컴팩트', '컴퓨터', '케이', '케이블', '케이스', '케이트', '켄타', '코드', '코디', '코딩', '코멘트', '코모', '코미디', '코믹', '코스', '코스프레', '코어', '코지', '코퍼레이션', '콘텐츠', '콜라보레이션', '콜렉터', '콤비', '쾌거', '쾌속', '쾌적', '쿄카', '쿠라', '쿠보', '쿠타', '쿠피', '쿨뷰티', '쿼드코어', '퀴즈', '큐어', '크게', '크기', '크랭크', '크로우', '크롤', '크리미널마인드', '크리스마스', '크리에이터', '크리에이티브', '클라우드', '클라이언트', '클래스', '클래식', '클럭', '클럽', '클로버', '클리', '클릭', '클린', '키노', '키드', '키사', '키스', '키유', '키코', '킬러', '킬로미터', '타가', '타겟', '타고', '타블렛', '타이', '타이틀', '타인', '타임', '타입', '타츠야', '타카', '타케이', '탄생', '탈옥', '탈출', '탈환', '탐색기', '탐정', '탑재', '태블릿', '태양', '탤런트', '탱크', '탱크탑', '터미널', '터치', '테두리', '테러', '테루', '테마', '테스트', '테이', '테이블', '테크닉', '텍스트', '텔레비전', '템포', '토끼', '토리', '토시', '토카', '토크', '토키', '톰크루즈', '통과', '통상', '통신', '통역', '통지', '통째', '통칭', '통쾌', '통합', '통해', '퇴치', '투명', '투성이', '투어', '투입', '투혼', '튀어', '튜너', '트랜센드', '트렌드', '트로이', '트윗', '특별', '특별상', '특보', '특성', '특수', '특수촬영', '특정', '특집', '특징', '티저', '티켓', '티파니', '팀워크', '파괴', '파나소닉', '파리', '파악', '파워', '파이', '파이널', '파일', '파일형식', '파커', '파크', '파트너', '파티', '판단', '판매', '판타지', '팔찌', '패널', '패밀리', '패배', '패션', '패자', '패키지', '퍼스트', '퍼스트어벤져', '퍼즐', '퍼포먼스', '페이', '페이도', '페이지', '편리', '편승', '편안', '편의', '편이', '편지', '편집', '편패', '평가', '평균', '평단', '평상시', '평생', '평소', '평판', '평화', '포기', '포드', '포로', '포맷', '포스터', '포스트', '포인트', '포즈', '포켓', '포토', '포토북', '포트', '포함', '폭로', '폭발', '폭스', '폭탄', '폭파', '폭풍', '폴더', '폴란드', '표시', '표적', '표정', '표준', '표현', '품질', '풍경', '프랑스', '프레', '프레임', '프로', '프로그램', '프로듀서', '프로모션', '프로세서', '프로세스', '프로젝트', '프로토콜', '프로파일링', '프로필', '프리', '프리미어', '프리미엄', '프리스트', '프시', '플래그', '플래시백', '플랫폼', '플러스', '플레이', '플레이어', '피로', '피부', '피카딜리', '피터', '피플지', '피하', '피해', '피해자', '픽셀', '핀란드', '필견', '필사', '필수', '필요', '필자', '핑크', '하나', '하나님', '하나로', '하늘', '하단', '하드', '하드디스크', '하드보일드', '하드웨어', '하루', '하룻밤', '하순', '하시모토', '하우스', '하워드', '하위', '하이브리드', '하이엔드', '하자', '학교', '학생', '학설', '학습', '학원', '한게임', '한계', '한국', '한마디', '한번', '한상태', '한새', '한숨', '한시', '한일', '한자리', '한장', '한적', '한정', '한지', '한층', '한편', '한화', '할당', '할리우드', '할인', '함정', '항목', '항상', '해결', '해금', '해기스', '해나', '해당', '해도', '해리슨', '해리포터', '해부', '해상도', '해석', '해설', '해소', '해외', '해이', '해일', '해자', '해제', '해주시', '해지', '해커', '해피', '해피피트', '핵심', '행동', '행복', '행사', '행운', '행위', '향상', '향해', '향후', '허드', '허용', '헤비', '헤세이', '헤어', '혁명', '혁신', '현대', '현상', '현실', '현역', '현장', '현재', '현지', '혐의', '협력', '형사', '형식', '형제', '형태', '혜택', '호감', '호러', '호러영화', '호빗', '호세', '호소', '호연', '호출', '호쾌', '호텔', '호평', '호화', '호화상품', '혹성탈출', '혼란', '혼자', '혼합', '홈즈', '홈페이지', '홍보', '홍콩', '화가', '화려', '화면', '화소', '화수', '화의', '화이트', '화이트칼라', '화전', '화제', '화질', '화해', '확대', '확보', '확산', '확인', '확장', '확장자', '확정', '확충', '환각', '환경', '환상', '환성', '환영', '활동', '활약', '활용', '활활', '황금사자상', '황금시대', '황제', '회견', '회등', '회사', '회선', '회원', '회의', '회장', '회전', '회화', '획기', '획득', '효과', '효율', '후계', '후년', '후리', '후미', '후반', '후보', '후유', '후의', '후지', '후지와라', '후커', '후쿠', '후회', '훈련', '휴대', '휴대전화', '휴대폰', '휴먼', '휴식', '휴잭맨', '휴지통', '흐름', '흔적', '흥미', '흥분', '흥행수입', '희망', '희생', '히나마츠리', '히데', '히로', '히로시', '히로시마', '히로유키', '히로인', '히어로', '히카리', '히토미', '히트']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0ae70b9a88b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocterm_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(docterm_tfidf).shape)\n",
    "print(tv.get_feature_names())[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝을 위한 데이터 준비\n",
    "- 자연어 처리를 위한 알고리즘으로 딥러닝 알고리즘을 사용하는 편이 성능이 좋은 결과를 얻을 수 있음\n",
    "- 특히, 순환 신경망(RNN, Recurrent Neural Network)을 주로 활용함\n",
    "- 그 중, LSTM(Long Short-Term Memory)를 활용함\n",
    "- LSTM은 입력게이트, 입력 조정 게이트, 출력 게이트, 망각 게이트, 셀 등의 요소로 구성되어있음\n",
    "- LSTM의 처리는 인간이 과거에 일어난 일을 전부 기억하지 못하기에, 자신에게 중요한 일만 선택해서 기억해 놓고 나중에 기억을 꺼내 보는 것과 유사함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 기사의 띄어쓰기\n",
    "- 책에 작성된 wakati라는 변수는 일본어로 띄어쓰기라는 의미로 space로 변경하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "dirs = ['it-life-hack', 'movie-enter']\n",
    "\n",
    "space = []\n",
    "label = []\n",
    "\n",
    "def spacing_okt(sentence):\n",
    "    tagged = okt.pos(sentence)\n",
    "    corrected = \"\"\n",
    "    for token in tagged:\n",
    "        if token[1] in ('Josa', 'PreEomi', 'Eomi', 'Suffix', 'Punctuation'):\n",
    "            corrected += \" \" + \"'\" + token[0] + \"'\" + \",\"\n",
    "        else:\n",
    "            corrected += \" \" + \"'\" + token[0] + \"'\" + \",\"\n",
    "    if corrected[0] == \" \":\n",
    "        corrected = corrected[1:]\n",
    "    return corrected\n",
    "\n",
    "for i, d in enumerate(dirs):\n",
    "    files = os.listdir('./data/' + d)\n",
    "\n",
    "    for file in files:\n",
    "        f = open('./data/' + d + '/' + file, 'r', encoding='utf-8')\n",
    "        text = f.read()\n",
    "\n",
    "        reg_text = re.sub(r'[0-9a-zA-Z]+', '', text)\n",
    "        reg_text = re.sub(r'[:;/+\\.-]', '', reg_text)\n",
    "        reg_text = re.sub(r'[\\s\\n]', '', reg_text)\n",
    "\n",
    "        space.append(spacing_okt(reg_text))\n",
    "\n",
    "        label.append(i)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "'구형', '에서', '금단', '의', '파워', '업', '!', '최신', '나', '소프트웨어', '를', '한꺼', '번', '에', '체크', '[', '플래시백', ']', '텔레비전', '이나', '와', '연', '계', '할수있는나', '프로세서', ',', '전환', '등', '재미있는가', '속속', '등장', '했다', '구형', '의', '금단', '이라고도', '할수있는', '파워', '업', '방법', '에서의', '최신', ',', '화제', '의', ',', '새로운', '보안', '소프트웨어', '까지', '한꺼', '번', '에', '소개', '합니다', '■', '인텔', '을', '에', '장착', '!', '구형', '은', '얼마나', '빨라질', '것', '인가', '?(', '위', ')', '인텔', '이', '최신', ''', '시리즈', ''', '를', '출시', '했다', '현재', '중', '에서도', '최고', '의', '성능', '을', '자랑', '하', '는', '이', '제품', '을', '구형', '의', '고속', '화', '를', '도모', '한다는', '점', '에서', '리뷰', '해보았다', '조금', '색다른', '리뷰', '가', '되지만', ',', '어느', '정도', '의', '효과', '가', '있는지', ',', '기', '대가', '크다', '■', '는사', '용하는가', '(', '인텔', '등', ')', '에서', '으로', '전환', '가능한', '하이브리드', ',', '하지', '만이', '와', '동시', '에도', '바뀐다', '■', '초기', '비용', ',', '업데이트', '비용', '모두', '무료', '!', '저스트', '시스템', ',', '도마뱀', '로그', '가', '인상', '적', '인', '보안', '소프트웨어', '현재', '는', '많은', '사용자', '들이에', '보안', '프로그램', '을', '도입', '하고', '있지만', ',', '그', '대부분', '은', '매년', ',', '엔', '정도', '드는', '업데이트', '비용', '과', '그', '절차', '에', '대해', '불만', '을', '가지', '고', '있다', '유료', '소프트웨어', '를', '이용', '하', '는', '사용자', '의약', '%', '는', '무료', '보안', '소프트웨어', '를', '알고있음에도', '불구', '하고', ',', '성능', '면', '에서', '뒤', '떨어지는게', '아니냐는', '불안', '에서', '도입', '을', '미루고있는', '상황', '이다', '■', '텔레비전', '의', '새로운', '활용', '방법', '을', '제안', '!', '의봄', '신상', '는와를', '연', '계', '는', '년월', '일', ',', '개인용', '데스크톱', '인', ''\"', '시리즈', '종류', '모델', '을', '월일', '부터', '판매', '한', '다', '고', '발표', '했다신', '상품', '은', '더', '강력해진', '녹화', '기능', '외', '에도', '시청', '·', '녹화', '기능', '에', '더해서', '업계', '최초', '로', '인기', '를', '연', '계', '한', ''', '트', '위트', '플러스', ''', '를', '추가', '하', '는', '등', '컴퓨터', '만의', '기능', '을', '탑재', '스마트폰', '홈', '네트워크', '대응', '도', '강화하고', ',\"', '안심', '간단', '쾌적', '\"', '한', '디지털', '엔터테인먼트', '를', '제안', '하', '여', ',', '주요', '모델', '에', '대해', '다음', '과', '같이', '기능', '강화', '를', '실시', '했다', '■', '마치', '축제', '같은', '출하', '식', '!', '렛츠', '노트', '출하', '시', '작', '월일', '에', '발매', '되는', ''', '의', '출하', '식', '이월', '일', '국내', '제', '조', '거점', '인', '고베', '공장', '에서', '열렸다', '동', '사의', '컴퓨터', '로는', '처음', '실시', '하', '는', '출하', '식', '으로', ',', '이', '제품', '에', '얼마나', '힘', '이', '들어가있는지', '알수있다', '[', '엡손', '정품', '잉크', ']', '잉크', '카트리지', '색', '세트', '엡손', '출판사', '입', '소문', '을', '본다',\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(space))\n",
    "print(space[0])\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 기사에 대한 처리를 실행하였으며, 작성한 데이터 셋의 크기와 값을 확인할 수 있음\n",
    "- space의 크기는 400으로, 이는 기사 수에 해당함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n",
      "   0\n",
      "0  '\n",
      "1  ,\n",
      "2   \n",
      "3  이\n",
      "4  다\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "word_freq = Counter(itertools.chain(* space))\n",
    "\n",
    "dic = []\n",
    "for word_uniq in word_freq.most_common():\n",
    "    dic.append(word_uniq[0])\n",
    "    \n",
    "print(len(dic))\n",
    "print(pd.DataFrame(dic).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 통해 dic의 크기가 1482인 것을 확인할 수 있음\n",
    "- 기사는 1482개로 구성되어있다는 것을 알 수 있으며, 상위 5단어는 ', , ,공백,이,다 라는 것을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "dic_inv = {}\n",
    "for i, word_uniq in enumerate(dic, start=1):\n",
    "    dic_inv.update({word_uniq: i})\n",
    "    \n",
    "print(len(dic_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[1, 93, 242, 1, 2, 3, 1, 7, 20, 1, 2, 3, 1, 157, 162, 1, 2, 3, 1, 8, 1, 2, 3, 1, 132, 262, 1, 2, 3, 1, 200, 1, 2, 3, 1, 65, 1, 2, 3, 1, 133, 73, 1, 2, 3, 1, 41, 1, 2, 3, 1, 70, 88, 39, 421, 26, 1, 2, 3, 1, 25, 1, 2, 3, 1, 19, 750, 1, 2, 3, 1, 176, 1, 2, 3, 1, 7, 1, 2, 3, 1, 182, 96, 1, 2, 3, 1, 173, 1, 2, 3, 1, 226, 156, 27, 338, 1, 2, 3, 1, 186, 1, 2, 3, 1, 406, 120, 80, 47, 1, 2, 3, 1, 4, 41, 1, 2, 3, 1, 66, 1, 2, 3, 1, 76, 1, 2, 3, 1, 97, 1, 2, 3, 1, 77, 36, 18, 6, 41, 1, 2, 3, 1, 88, 15, 79, 20, 1, 2, 3, 1, 2, 1, 2, 3, 1, 47, 292, 1, 2, 3, 1, 92, 1, 2, 3, 1, 118, 61, 18, 6, 14, 1, 2, 3, 1, 179, 179, 1, 2, 3, 1, 92, 52, 1, 2, 3, 1, 108, 5, 1, 2, 3, 1, 93, 242, 1, 2, 3, 1, 8, 1, 2, 3, 1, 157, 162, 1, 2, 3, 1, 4, 28, 11, 22, 1, 2, 3, 1, 77, 36, 18, 6, 1, 2, 3, 1, 132, 262, 1, 2, 3, 1, 200, 1, 2, 3, 1, 181, 244, 1, 2, 3, 1, 7, 20, 8, 1, 2, 3, 1, 133, 73, 1, 2, 3, 1, 2, 1, 2, 3, 1, 38, 44, 1, 2, 3, 1, 8, 1, 2, 3, 1, 2, 1, 2, 3, 1, 224, 15, 109, 1, 2, 3, 1, 50, 165, 1, 2, 3, 1, 70, 88, 39, 421, 26, 1, 2, 3, 1, 100, 13, 1, 2, 3, 1, 19, 750, 1, 2, 3, 1, 176, 1, 2, 3, 1, 7, 1, 2, 3, 1, 70, 69, 1, 2, 3, 1, 191, 32, 5, 1, 2, 3, 1, 112, 1, 2, 3, 1, 29, 406, 1, 2, 3, 1, 10, 1, 2, 3, 1, 7, 1, 2, 3, 1, 52, 335, 1, 2, 3, 1, 65, 1, 2, 3, 1, 93, 242, 1, 2, 3, 1, 23, 1, 2, 3, 1, 264, 46, 41, 1, 2, 3, 1, 634, 28, 271, 1, 2, 3, 1, 35, 1, 2, 3, 1, 29, 14, 1, 2, 3, 1, 151, 60, 1, 2, 3, 1, 113, 1, 2, 3, 1, 59, 1, 2, 3, 1, 29, 406, 1, 2, 3, 1, 4, 1, 2, 3, 1, 133, 73, 1, 2, 3, 1, 1, 1, 2, 3, 1, 27, 21, 146, 1, 2, 3, 1, 1, 1, 2, 3, 1, 25, 1, 2, 3, 1, 154, 27, 1, 2, 3, 1, 108, 5, 1, 2, 3, 1, 188, 118, 1, 2, 3, 1, 147, 1, 2, 3, 1, 7, 20, 22, 1, 2, 3, 1, 133, 11, 1, 2, 3, 1, 8, 1, 2, 3, 1, 95, 160, 1, 2, 3, 1, 10, 1, 2, 3, 1, 34, 257, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 4, 1, 2, 3, 1, 44, 89, 1, 2, 3, 1, 10, 1, 2, 3, 1, 93, 242, 1, 2, 3, 1, 8, 1, 2, 3, 1, 11, 179, 1, 2, 3, 1, 38, 1, 2, 3, 1, 25, 1, 2, 3, 1, 22, 55, 1, 2, 3, 1, 19, 5, 6, 1, 2, 3, 1, 219, 1, 2, 3, 1, 7, 20, 1, 2, 3, 1, 21, 249, 1, 2, 3, 1, 42, 50, 277, 5, 1, 2, 3, 1, 153, 157, 1, 2, 3, 1, 309, 5, 201, 1, 2, 3, 1, 21, 249, 1, 2, 3, 1, 14, 1, 2, 3, 1, 62, 13, 43, 1, 2, 3, 1, 2, 1, 2, 3, 1, 26, 274, 1, 2, 3, 1, 49, 22, 1, 2, 3, 1, 8, 1, 2, 3, 1, 477, 74, 1, 2, 3, 1, 14, 1, 2, 3, 1, 18, 6, 13, 1, 2, 3, 1, 2, 1, 2, 3, 1, 16, 1, 2, 3, 1, 37, 14, 1, 2, 3, 1, 96, 5, 1, 2, 3, 1, 112, 1, 2, 3, 1, 6, 17, 1, 2, 3, 1, 56, 9, 6, 14, 1, 2, 3, 1, 60, 1, 2, 3, 1, 29, 406, 1, 2, 3, 1, 92, 1, 2, 3, 1, 59, 1, 2, 3, 1, 7, 20, 1, 2, 3, 1, 48, 15, 1, 2, 3, 1, 47, 292, 1, 2, 3, 1, 14, 160, 19, 1, 2, 3, 1, 9, 4, 209, 21, 57, 1, 2, 3, 1, 2, 1, 2, 3, 1, 9, 13, 1, 2, 3, 1, 43, 4, 1, 2, 3, 1, 66, 1, 2, 3, 1, 98, 27, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 138, 846, 5, 1, 2, 3, 1, 112, 1, 2, 3, 1, 234, 16, 1, 2, 3, 1, 80, 56, 1, 2, 3, 1, 2, 1, 2, 3, 1, 200, 129, 4, 39, 1, 2, 3, 1, 80, 56, 1, 2, 3, 1, 55, 171, 1, 2, 3, 1, 90, 238, 1, 2, 3, 1, 65, 1, 2, 3, 1, 192, 24, 39, 1, 2, 3, 1, 27, 24, 442, 1, 2, 3, 1, 2, 1, 2, 3, 1, 22, 46, 566, 1, 2, 3, 1, 15, 30, 1, 2, 3, 1, 14, 1, 2, 3, 1, 29, 45, 1, 2, 3, 1, 91, 1, 2, 3, 1, 29, 1, 2, 3, 1, 50, 165, 1, 2, 3, 1, 70, 88, 39, 421, 26, 1, 2, 3, 1, 188, 118, 1, 2, 3, 1, 6, 1, 2, 3, 1, 251, 23, 1, 2, 3, 1, 17, 56, 34, 1, 2, 3, 1, 85, 4, 7, 1, 2, 3, 1, 50, 165, 1, 2, 3, 1, 88, 15, 30, 281, 1, 2, 3, 1, 10, 1, 2, 3, 1, 22, 110, 1, 2, 3, 1, 9, 11, 1, 2, 3, 1, 18, 13, 43, 1, 2, 3, 1, 2, 1, 2, 3, 1, 30, 1, 2, 3, 1, 37, 63, 150, 1, 2, 3, 1, 23, 1, 2, 3, 1, 128, 149, 1, 2, 3, 1, 2, 1, 2, 3, 1, 222, 1, 2, 3, 1, 49, 22, 1, 2, 3, 1, 57, 6, 1, 2, 3, 1, 200, 129, 4, 39, 1, 2, 3, 1, 80, 56, 1, 2, 3, 1, 74, 1, 2, 3, 1, 30, 1, 2, 3, 1, 261, 215, 1, 2, 3, 1, 7, 1, 2, 3, 1, 37, 42, 1, 2, 3, 1, 286, 43, 1, 2, 3, 1, 10, 1, 2, 3, 1, 14, 13, 1, 2, 3, 1, 11, 1, 2, 3, 1, 18, 5, 1, 2, 3, 1, 101, 238, 1, 2, 3, 1, 70, 88, 39, 421, 26, 1, 2, 3, 1, 25, 1, 2, 3, 1, 4, 56, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 17, 56, 34, 1, 2, 3, 1, 8, 229, 1, 2, 3, 1, 518, 1, 2, 3, 1, 6, 1, 2, 3, 1, 90, 238, 1, 2, 3, 1, 50, 165, 1, 2, 3, 1, 70, 88, 39, 421, 26, 1, 2, 3, 1, 25, 1, 2, 3, 1, 230, 11, 18, 114, 7, 22, 1, 2, 3, 1, 286, 93, 1, 2, 3, 1, 9, 11, 1, 2, 3, 1, 2, 1, 2, 3, 1, 95, 160, 1, 2, 3, 1, 54, 1, 2, 3, 1, 7, 20, 1, 2, 3, 1, 485, 1, 2, 3, 1, 507, 26, 13, 6, 51, 1, 2, 3, 1, 33, 32, 710, 6, 1, 2, 3, 1, 286, 165, 1, 2, 3, 1, 7, 20, 1, 2, 3, 1, 22, 110, 1, 2, 3, 1, 10, 1, 2, 3, 1, 61, 202, 11, 18, 6, 1, 2, 3, 1, 45, 395, 1, 2, 3, 1, 4, 5, 1, 2, 3, 1, 112, 1, 2, 3, 1, 406, 120, 80, 47, 1, 2, 3, 1, 8, 1, 2, 3, 1, 224, 15, 109, 1, 2, 3, 1, 241, 56, 1, 2, 3, 1, 181, 244, 1, 2, 3, 1, 10, 1, 2, 3, 1, 44, 165, 1, 2, 3, 1, 65, 1, 2, 3, 1, 8, 769, 1, 2, 3, 1, 73, 45, 1, 2, 3, 1, 6, 66, 25, 1, 2, 3, 1, 76, 1, 2, 3, 1, 97, 1, 2, 3, 1, 6, 1, 2, 3, 1, 149, 123, 1, 2, 3, 1, 31, 1, 2, 3, 1, 2, 1, 2, 3, 1, 69, 29, 56, 1, 2, 3, 1, 129, 24, 96, 727, 1, 2, 3, 1, 29, 1, 2, 3, 1, 1, 12, 1, 2, 3, 1, 27, 21, 146, 1, 2, 3, 1, 255, 368, 1, 2, 3, 1, 55, 351, 1, 2, 3, 1, 10, 1, 2, 3, 1, 123, 31, 1, 2, 3, 1, 63, 58, 1, 2, 3, 1, 216, 128, 1, 2, 3, 1, 19, 1, 2, 3, 1, 5, 1, 2, 3, 1, 11, 1, 2, 3, 1, 119, 169, 1, 2, 3, 1, 108, 5, 73, 1, 2, 3, 1, 45, 89, 1, 2, 3, 1, 23, 1, 2, 3, 1, 142, 1, 2, 3, 1, 243, 167, 42, 83, 1, 2, 3, 1, 681, 38, 1, 2, 3, 1, 16, 160, 1, 2, 3, 1, 189, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 27, 350, 1, 2, 3, 1, 64, 1, 2, 3, 1, 681, 38, 1, 2, 3, 1, 16, 160, 1, 2, 3, 1, 7, 1, 2, 3, 1, 142, 42, 20, 1, 2, 3, 1, 200, 97, 1, 2, 3, 1, 133, 234, 1, 2, 3, 1, 15, 1, 2, 3, 1, 29, 16, 1, 2, 3, 1, 25, 1, 2, 3, 1, 76, 1, 2, 3, 1, 97, 1, 2, 3, 1, 19, 1, 2, 3, 1, 1, 1, 2, 3, 1, 39, 1, 2, 3, 1, 113, 39, 1, 2, 3, 1, 226, 105, 24, 1, 2, 3, 1, 1, 1, 2, 3, 1, 25, 1, 2, 3, 1, 235, 14, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 92, 1, 2, 3, 1, 439, 497, 58, 1, 2, 3, 1, 43, 8, 1, 2, 3, 1, 16, 160, 1, 2, 3, 1, 10, 1, 2, 3, 1, 293, 118, 1, 2, 3, 1, 24, 46, 39, 245, 1, 2, 3, 1, 498, 1, 2, 3, 1, 217, 39, 262, 96, 1, 2, 3, 1, 37, 206, 1, 2, 3, 1, 22, 1, 2, 3, 1, 243, 38, 9, 11, 1, 2, 3, 1, 2, 12, 1, 2, 3, 1, 165, 223, 1, 2, 3, 1, 140, 162, 1, 2, 3, 1, 499, 91, 1, 2, 3, 1, 12, 1, 2, 3, 1, 19, 1, 2, 3, 1, 102, 13, 239, 1, 2, 3, 1, 222, 58, 208, 29, 362, 39, 1, 2, 3, 1, 25, 1, 2, 3, 1, 44, 165, 1, 2, 3, 1, 9, 1, 2, 3, 1, 71, 1, 2, 3, 1, 2, 1, 2, 3, 1, 68, 75, 1, 2, 3, 1, 55, 351, 1, 2, 3, 1, 7, 1, 2, 3, 1, 37, 42, 1, 2, 3, 1, 5, 114, 1, 2, 3, 1, 74, 1, 2, 3, 1, 187, 4, 1, 2, 3, 1, 16, 160, 1, 2, 3, 1, 243, 38, 1, 2, 3, 1, 25, 1, 2, 3, 1, 127, 27, 1, 2, 3, 1, 108, 5, 1, 2, 3, 1, 112, 1, 2, 3, 1, 46, 104, 1, 2, 3, 1, 417, 44, 1, 2, 3, 1, 187, 23, 1, 2, 3, 1, 154, 9, 1, 2, 3, 1, 172, 1, 2, 3, 1, 65, 1, 2, 3, 1, 531, 232, 1, 2, 3, 1, 170, 39, 1, 2, 3, 1, 154, 9, 1, 2, 3, 1, 27, 1, 2, 3, 1, 53, 1, 2, 3, 1, 123, 31, 1, 2, 3, 1, 7, 1, 2, 3, 1, 119, 128, 1, 2, 3, 1, 62, 6, 1, 2, 3, 1, 1, 1, 2, 3, 1, 8, 1, 2, 3, 1, 154, 9, 1, 2, 3, 1, 172, 1, 2, 3, 1, 4, 123, 1, 2, 3, 1, 31, 1, 2, 3, 1, 134, 163, 1, 2, 3, 1, 44, 1, 2, 3, 1, 153, 1, 2, 3, 1, 106, 219, 1, 2, 3, 1, 29, 1, 2, 3, 1, 11, 287, 1, 2, 3, 1, 72, 52, 1, 2, 3, 1, 7, 20, 1, 2, 3, 1, 265, 466, 5, 1, 2, 3, 1, 98, 1, 2, 3, 1, 17, 8, 1, 2, 3, 1, 439, 497, 58, 1, 2, 3, 1, 15, 6, 1, 2, 3, 1, 212, 114, 1, 2, 3, 1, 127, 27, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 154, 9, 1, 2, 3, 1, 172, 1, 2, 3, 1, 48, 15, 1, 2, 3, 1, 2, 1, 2, 3, 1, 4, 1, 2, 3, 1, 44, 89, 1, 2, 3, 1, 7, 1, 2, 3, 1, 264, 46, 41, 1, 2, 3, 1, 437, 1, 2, 3, 1, 4, 1, 2, 3, 1, 85, 26, 14, 18, 6, 13, 1, 2, 3, 1, 230, 36, 18, 5, 1, 2, 3, 1, 173, 1, 2, 3, 1, 847, 210, 1, 2, 3, 1, 49, 89, 1, 2, 3, 1, 532, 96, 1, 2, 3, 1, 186, 1, 2, 3, 1, 532, 96, 1, 2, 3, 1, 82, 39, 21, 13, 1, 2, 3, 1, 309, 1, 2, 3, 1, 79, 39, 1, 2, 3, 1, 847, 210, 1, 2, 3, 1, 154, 216, 17, 1, 2, 3, 1, 110, 1, 2, 3, 1, 70, 86, 1, 2, 3, 1, 10, 1, 2, 3, 1, 78, 5, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "space_id = [ [ dic_inv[word] for word in spaceWord ] for spaceWord in space ]\n",
    "\n",
    "print(len(space_id))\n",
    "print(space_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "\n",
    "space_id = sequence.pad_sequences(np.array(space_id), maxlen=3382, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "label = np.array(label)\n",
    "\n",
    "print(space_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 리스트 길이 정리 수행(TF, Keras 버전 매칭 때문에 실행하지 않음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 주제 추출을 위한 데이터 준비\n",
    "- 카테고리에 포함되어 있는 주제를 추출하고, 분류의 근거를 이해하는 것이 목표임\n",
    "- 주제를 추출하는 방법 중 네트워크 분석(클러스트링)을 위한 전처리를 수행\n",
    "- 네트워크(그래프)는 대상과 대상의 관계를 표현하는 방법 중 하나임\n",
    "- 네트워크로 표현할 수 있는 것에는 SNS 친구 관계, 문서에 포함된 단어의 동시 출현 관계 등이 있음\n",
    "- 단어 쌍의 발생횟수가 많을 수록 에지의 가중치는 커지게 됨\n",
    "- 단어 문서 행렬로부터 단어 쌍의 유사도를 계산하고, 에지 리스트를 작성할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 문서 행렬 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "dirs = ['it-life-hack', 'movie-enter']\n",
    "\n",
    "docterm = []\n",
    "label = []\n",
    "tmp1 = []\n",
    "tmp2 = ''\n",
    "\n",
    "for i, d in enumerate(dirs):\n",
    "    files = os.listdir('./data/' + d)\n",
    "    \n",
    "    for file in files:\n",
    "        f = open('./data/' + d + '/' + file, 'r', encoding='utf-8')\n",
    "        text = f.read()\n",
    "        \n",
    "        reg_text = re.sub(r'[0-9a-zA-Z]+', '', text)\n",
    "        reg_text = re.sub(r'[:;/+\\.-]', '', reg_text)\n",
    "        reg_text = re.sub(r'[\\s\\n]', '', reg_text)\n",
    "        reg_text = reg_text.replace('\\n','')        \n",
    "        \n",
    "        for token in okt.nouns(reg_text):\n",
    "            tmp1.append(token)\n",
    "            tmp2 = ' '.join(tmp1)\n",
    "        docterm.append(tmp2)\n",
    "        tmp1 = []\n",
    "        \n",
    "        label.append(i)\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>562</th>\n",
       "      <th>563</th>\n",
       "      <th>564</th>\n",
       "      <th>565</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2    3    4    5    6         7    8    9    ...  \\\n",
       "0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.057486  0.0  0.0  ...   \n",
       "1  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "2  0.0  0.035539  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "3  0.0  0.000000  0.064138  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "4  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "\n",
       "        562  563  564      565       566  567  568       569  570  571  \n",
       "0  0.000000  0.0  0.0  0.06596  0.000000  0.0  0.0  0.076403  0.0  0.0  \n",
       "1  0.000000  0.0  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.0  \n",
       "2  0.044132  0.0  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.0  \n",
       "3  0.064138  0.0  0.0  0.00000  0.112522  0.0  0.0  0.000000  0.0  0.0  \n",
       "4  0.000000  0.0  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.0  \n",
       "\n",
       "[5 rows x 572 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0.05, max_df=0.5)\n",
    "docterm_tv = tv.fit_transform(np.array(docterm))\n",
    "docterm_tfidf = docterm_tv.toarray()\n",
    "\n",
    "docterm_tfidf = pd.DataFrame(docterm_tfidf)\n",
    "docterm_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>563</th>\n",
       "      <th>564</th>\n",
       "      <th>565</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2    3    4    5    6         7    8    9  ...  563  \\\n",
       "0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.057486  0.0  0.0  ...  0.0   \n",
       "1  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...  0.0   \n",
       "2  0.0  0.035539  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...  0.0   \n",
       "3  0.0  0.000000  0.064138  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...  0.0   \n",
       "4  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...  0.0   \n",
       "\n",
       "   564      565       566  567  568       569  570  571  label  \n",
       "0  0.0  0.06596  0.000000  0.0  0.0  0.076403  0.0  0.0      0  \n",
       "1  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.0      0  \n",
       "2  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.0      0  \n",
       "3  0.0  0.00000  0.112522  0.0  0.0  0.000000  0.0  0.0      0  \n",
       "4  0.0  0.00000  0.000000  0.0  0.0  0.000000  0.0  0.0      0  \n",
       "\n",
       "[5 rows x 573 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = pd.DataFrame(label)\n",
    "label = label.rename(columns={0:'label'})\n",
    "\n",
    "docterm_df = pd.concat([docterm_tfidf, label], axis=1)\n",
    "docterm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 통해 572개의 단어가 선택된 것을 확인할 수 있음\n",
    "- 단어 문서 행렬과 기사 카테고리인 label 열을 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사도 계산\n",
    "- 유사도 계산은 코사인 유사도를 이용\n",
    "- 두 개의 단어가 출현하는 문서가 어느 정도 유사한지를 측정하기 위해서 단어가 출현하는 문서 벡터의 각도를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>562</th>\n",
       "      <th>563</th>\n",
       "      <th>564</th>\n",
       "      <th>565</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141408</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186522</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083729</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.141408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101792</td>\n",
       "      <td>0.128885</td>\n",
       "      <td>0.061311</td>\n",
       "      <td>0.268409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179446</td>\n",
       "      <td>0.113796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184275</td>\n",
       "      <td>0.106287</td>\n",
       "      <td>0.193323</td>\n",
       "      <td>0.079040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104116</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035460</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.069778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082391</td>\n",
       "      <td>0.074838</td>\n",
       "      <td>0.324744</td>\n",
       "      <td>0.091507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147545</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072470</td>\n",
       "      <td>0.043957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.101792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015136</td>\n",
       "      <td>0.109526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.184275</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>0.120151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051116</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106287</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230558</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.105228</td>\n",
       "      <td>0.017947</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195485</td>\n",
       "      <td>0.043520</td>\n",
       "      <td>0.025785</td>\n",
       "      <td>0.206781</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.083729</td>\n",
       "      <td>0.193323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>0.112827</td>\n",
       "      <td>0.218378</td>\n",
       "      <td>0.203307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052977</td>\n",
       "      <td>0.146782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.147886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.141408  0.104116  0.000000  0.009311  0.000000  0.000000   \n",
       "1    0.141408  1.000000  0.062866  0.000000  0.101792  0.128885  0.061311   \n",
       "2    0.104116  0.062866  1.000000  0.049026  0.000000  0.035460  0.057350   \n",
       "3    0.000000  0.000000  0.049026  1.000000  0.082391  0.074838  0.324744   \n",
       "4    0.009311  0.101792  0.000000  0.082391  1.000000  0.064864  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "567  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "568  0.035551  0.184275  0.012399  0.000000  0.042532  0.120151  0.000000   \n",
       "569  0.000000  0.106287  0.014712  0.000000  0.000000  0.230558  0.043875   \n",
       "570  0.083729  0.193323  0.000000  0.000000  0.000000  0.048021  0.000000   \n",
       "571  0.000000  0.079040  0.025075  0.000000  0.000000  0.071475  0.112827   \n",
       "\n",
       "          7         8         9    ...       562       563       564  \\\n",
       "0    0.099843  0.000000  0.008391  ...  0.000000  0.000000  0.000000   \n",
       "1    0.268409  0.000000  0.155917  ...  0.104926  0.000000  0.000000   \n",
       "2    0.076619  0.000000  0.046448  ...  0.017823  0.000000  0.000000   \n",
       "3    0.091507  0.000000  0.000000  ...  0.147545  0.037859  0.000000   \n",
       "4    0.006031  0.000000  0.009473  ...  0.000000  0.131242  0.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "567  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "568  0.043602  0.000000  0.442460  ...  0.000000  0.000000  0.000000   \n",
       "569  0.105228  0.017947  0.014756  ...  0.195485  0.043520  0.025785   \n",
       "570  0.048749  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "571  0.218378  0.203307  0.000000  ...  0.052977  0.146782  0.000000   \n",
       "\n",
       "          565       566  567       568       569       570       571  \n",
       "0    0.186522  0.022011  0.0  0.035551  0.000000  0.083729  0.000000  \n",
       "1    0.179446  0.113796  0.0  0.184275  0.106287  0.193323  0.079040  \n",
       "2    0.112102  0.069778  0.0  0.012399  0.014712  0.000000  0.025075  \n",
       "3    0.072470  0.043957  0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "4    0.015136  0.109526  0.0  0.042532  0.000000  0.000000  0.000000  \n",
       "..        ...       ...  ...       ...       ...       ...       ...  \n",
       "567  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "568  0.051116  0.037441  0.0  1.000000  0.039360  0.000000  0.000000  \n",
       "569  0.206781  0.036000  0.0  0.039360  1.000000  0.000000  0.152729  \n",
       "570  0.013978  0.009529  0.0  0.000000  0.000000  1.000000  0.000000  \n",
       "571  0.026828  0.147886  0.0  0.000000  0.152729  0.000000  1.000000  \n",
       "\n",
       "[572 rows x 572 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docterm_0 = docterm_df[docterm_df['label'] == 0]\n",
    "docterm_0 = docterm_0.drop('label', axis=1)\n",
    "\n",
    "sim0 = cosine_similarity(docterm_0.T)\n",
    "sim0_df = pd.DataFrame(sim0)\n",
    "\n",
    "sim0_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label이 0인 문서의 유사도 계산\n",
    "- 결과를 통해 단어 쌍의 코사인 유사도를 행렬 형식으로 시각화된 것을 확인할 수 있음\n",
    "- 총 572개의 단어 쌍의 유사도가 계산된 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동시 출현어 에지 리스트 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (0, 0)\n",
      "1    (0, 1)\n",
      "2    (0, 2)\n",
      "3    (0, 3)\n",
      "4    (0, 4)\n",
      "dtype: object\n",
      "0    1.000000\n",
      "1    0.141408\n",
      "2    0.104116\n",
      "3    0.000000\n",
      "4    0.009311\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sim0_stack = sim0_df.stack()\n",
    "\n",
    "index = pd.Series(sim0_stack.index.values)\n",
    "value = pd.Series(sim0_stack.values)\n",
    "\n",
    "print(index.head())\n",
    "print(value.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>0.557745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0.806134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.522477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>0.608517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>0.761323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node1  node2    weight\n",
       "0      0    315  0.557745\n",
       "1      0    415  0.806134\n",
       "2      1    143  0.522477\n",
       "3      1    277  0.608517\n",
       "4      2    130  0.761323"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp3 = []\n",
    "tmp4 = []\n",
    "for i in range(len(index)):\n",
    "    if value[i] >=0.5 and value[i] <= 0.9:\n",
    "        tmp1 = str(index[i][0]) + ' ' + str(index[i][1])\n",
    "        tmp2 = [int(s) for s in tmp1.split()]\n",
    "        tmp3.append(tmp2)\n",
    "        tmp4 = np.append(tmp4, value[i])\n",
    "\n",
    "tmp3 = pd.DataFrame(tmp3)\n",
    "tmp3 = tmp3.rename(columns={0:'node1', 1:'node2'})\n",
    "tmp4 = pd.DataFrame(tmp4)\n",
    "tmp4 = tmp4.rename(columns={0:'weight'})\n",
    "sim0_list = pd.concat([tmp3, tmp4], axis=1)\n",
    "\n",
    "sim0_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬 형식을 리스트 형식으로 변환 후, 동시 출현어 에지 리스트 작성을 수행하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>562</th>\n",
       "      <th>563</th>\n",
       "      <th>564</th>\n",
       "      <th>565</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148350</td>\n",
       "      <td>0.191087</td>\n",
       "      <td>0.057453</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220078</td>\n",
       "      <td>0.054329</td>\n",
       "      <td>0.181650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075351</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>0.035375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123998</td>\n",
       "      <td>0.112525</td>\n",
       "      <td>0.043856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.136265</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191087</td>\n",
       "      <td>0.075351</td>\n",
       "      <td>0.238951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171711</td>\n",
       "      <td>0.179447</td>\n",
       "      <td>0.097663</td>\n",
       "      <td>0.148041</td>\n",
       "      <td>0.096522</td>\n",
       "      <td>0.132965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099789</td>\n",
       "      <td>0.032837</td>\n",
       "      <td>0.032350</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.101590</td>\n",
       "      <td>0.081628</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>0.128508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057453</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244826</td>\n",
       "      <td>0.175445</td>\n",
       "      <td>0.070080</td>\n",
       "      <td>0.121288</td>\n",
       "      <td>0.084527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354713</td>\n",
       "      <td>0.155318</td>\n",
       "      <td>0.096432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028629</td>\n",
       "      <td>0.046902</td>\n",
       "      <td>0.151271</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>0.101590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146935</td>\n",
       "      <td>0.060094</td>\n",
       "      <td>0.163279</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099991</td>\n",
       "      <td>0.175140</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076181</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.218902</td>\n",
       "      <td>0.029203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.123998</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>0.081628</td>\n",
       "      <td>0.028629</td>\n",
       "      <td>0.086077</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>0.042152</td>\n",
       "      <td>0.085231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068540</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.116465</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>0.076181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020068</td>\n",
       "      <td>0.222647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.046902</td>\n",
       "      <td>0.179107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080225</td>\n",
       "      <td>0.166278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066585</td>\n",
       "      <td>0.304150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043856</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>0.151271</td>\n",
       "      <td>0.190101</td>\n",
       "      <td>0.175752</td>\n",
       "      <td>0.063254</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.218902</td>\n",
       "      <td>0.020068</td>\n",
       "      <td>0.066585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.094428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096539</td>\n",
       "      <td>0.156302</td>\n",
       "      <td>0.145360</td>\n",
       "      <td>0.151097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.093802</td>\n",
       "      <td>0.140619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.222647</td>\n",
       "      <td>0.304150</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.000000  0.148350  0.191087  0.057453  0.022960  0.000000   \n",
       "1    0.000000  1.000000  0.000000  0.075351  0.133921  0.031064  0.000000   \n",
       "2    0.148350  0.000000  1.000000  0.238951  0.000000  0.005220  0.003880   \n",
       "3    0.191087  0.075351  0.238951  1.000000  0.171711  0.179447  0.097663   \n",
       "4    0.057453  0.133921  0.000000  0.171711  1.000000  0.244826  0.175445   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "567  0.000000  0.000000  0.069018  0.101590  0.000000  0.146935  0.060094   \n",
       "568  0.015526  0.123998  0.032848  0.081628  0.028629  0.086077  0.048455   \n",
       "569  0.000000  0.112525  0.000000  0.026389  0.046902  0.179107  0.000000   \n",
       "570  0.000000  0.043856  0.007370  0.140094  0.151271  0.190101  0.175752   \n",
       "571  0.094428  0.000000  0.000000  0.128508  0.000000  0.096539  0.156302   \n",
       "\n",
       "          7         8         9    ...       562       563       564  \\\n",
       "0    0.220078  0.054329  0.181650  ...  0.076088  0.000000  0.000000   \n",
       "1    0.030820  0.035375  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2    0.136265  0.042658  0.000000  ...  0.000000  0.006205  0.000000   \n",
       "3    0.148041  0.096522  0.132965  ...  0.099789  0.032837  0.032350   \n",
       "4    0.070080  0.121288  0.084527  ...  0.354713  0.155318  0.096432   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "567  0.163279  0.061129  0.000000  ...  0.000000  0.099991  0.175140   \n",
       "568  0.042152  0.085231  0.000000  ...  0.000000  0.068540  0.165084   \n",
       "569  0.080225  0.166278  0.000000  ...  0.000000  0.041164  0.000000   \n",
       "570  0.063254  0.041775  0.017490  ...  0.000000  0.003391  0.000000   \n",
       "571  0.145360  0.151097  0.000000  ...  0.013824  0.093802  0.140619   \n",
       "\n",
       "          565       566       567       568       569       570       571  \n",
       "0    0.000000  0.032315  0.000000  0.015526  0.000000  0.000000  0.094428  \n",
       "1    0.000000  0.000000  0.000000  0.123998  0.112525  0.043856  0.000000  \n",
       "2    0.000000  0.007348  0.069018  0.032848  0.000000  0.007370  0.000000  \n",
       "3    0.022189  0.114986  0.101590  0.081628  0.026389  0.140094  0.128508  \n",
       "4    0.000000  0.091956  0.000000  0.028629  0.046902  0.151271  0.000000  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "567  0.068097  0.033445  1.000000  0.076181  0.019795  0.218902  0.029203  \n",
       "568  0.116465  0.023836  0.076181  1.000000  0.000000  0.020068  0.222647  \n",
       "569  0.312502  0.000000  0.019795  0.000000  1.000000  0.066585  0.304150  \n",
       "570  0.000000  0.004016  0.218902  0.020068  0.066585  1.000000  0.080791  \n",
       "571  0.000000  0.025578  0.029203  0.222647  0.304150  0.080791  1.000000  \n",
       "\n",
       "[572 rows x 572 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docterm_1 = docterm_df[docterm_df['label'] == 1]\n",
    "docterm_1 = docterm_1.drop('label', axis=1)\n",
    "\n",
    "sim1 = cosine_similarity(docterm_1.T)\n",
    "sim1_df = pd.DataFrame(sim1)\n",
    "\n",
    "sim1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (0, 0)\n",
      "1    (0, 1)\n",
      "2    (0, 2)\n",
      "3    (0, 3)\n",
      "4    (0, 4)\n",
      "dtype: object\n",
      "0    1.000000\n",
      "1    0.000000\n",
      "2    0.148350\n",
      "3    0.191087\n",
      "4    0.057453\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sim1_stack = sim1_df.stack()\n",
    "\n",
    "index = pd.Series(sim1_stack.index.values)\n",
    "value = pd.Series(sim1_stack.values)\n",
    "\n",
    "print(index.head())\n",
    "print(value.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>239</td>\n",
       "      <td>0.552359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>386</td>\n",
       "      <td>0.505525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>533</td>\n",
       "      <td>0.504504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>0.548772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>325</td>\n",
       "      <td>0.522079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node1  node2    weight\n",
       "0      1    239  0.552359\n",
       "1      2    386  0.505525\n",
       "2      2    533  0.504504\n",
       "3      7    168  0.548772\n",
       "4     10    325  0.522079"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp3 = []\n",
    "tmp4 = []\n",
    "for i in range(len(index)):\n",
    "    if value[i] >=0.5 and value[i] <= 0.9:\n",
    "        tmp1 = str(index[i][0]) + ' ' + str(index[i][1])\n",
    "        tmp2 = [int(s) for s in tmp1.split()]\n",
    "        tmp3.append(tmp2)\n",
    "        tmp4 = np.append(tmp4, value[i])\n",
    "\n",
    "tmp3 = pd.DataFrame(tmp3)\n",
    "tmp3 = tmp3.rename(columns={0:'node1', 1:'node2'})\n",
    "tmp4 = pd.DataFrame(tmp4)\n",
    "tmp4 = tmp4.rename(columns={0:'weight'})\n",
    "sim1_list = pd.concat([tmp3, tmp4], axis=1)\n",
    "\n",
    "sim1_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 작성한 데이터 셋을 사용해 NetworkX를 사용한 단어의 동시 출현 네트워크를 생성하고, 주제를 추출할 수 있음\n",
    "- NetworkX는 파이썬에서 사용할 수 있는 네트워크 분석용 패키지임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-gram 에지 리스트\n",
    "- 단어가 어떤 순서로 출현했는지 어순을 고려할 필요가 있을 때는 N-gram을 활용\n",
    "- N-gram이란 문장을 연속된 N개의 문자로 분할하는 방법임\n",
    "- 인터넷 검색 시스템의 인덱스로 사용되고 있음  \n",
    "\n",
    "\n",
    "#### 문장 \"ㄱㄴㄷㄹㅁ\"을 N개의 문자로 분할하면 다음과 같음\n",
    "- 1-gram(유니그램) : ㄱ|ㄴ|ㄷ|ㄹ|ㅁ\n",
    "- 2-gram(바이그램) : ㄱㄴ|ㄴㄷ|ㄷㄹ|ㄹㅁ\n",
    "- 3-gram(트라이그램) : ㄱㄴㄷ|ㄴㄷㄹ|ㄷㄹㅁ  \n",
    "\n",
    "\n",
    "#### 문장 \"오늘은 맑음입니다.\"을 N개의 문자로 분할하면 다음과 같음\n",
    "- 1-gram(유니그램) : 오늘|은|맑음|입니다|.\n",
    "- 2-gram(바이그램) : 오늘-은|은-맑음|맑음-입니다|입니다-.\n",
    "- 3-gram(트라이그램) : 오늘-은-맑음|은-맑음-입니다|맑음-입니다-.  \n",
    "\n",
    "\n",
    "- 네트워크 분석에는 2-gram 모델을 이용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['오늘', '은'], ['은', '맑음'], ['맑음', '입니다'], ['입니다', '.']]\n"
     ]
    }
   ],
   "source": [
    "word = ['오늘', '은', '맑음', '입니다', '.']\n",
    "bigram = []\n",
    "\n",
    "for i in range(len(word)-1):\n",
    "     bigram.append([word[i], word[i+1]])\n",
    "\n",
    "print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['오늘', '은', '맑음'], ['은', '맑음', '입니다'], ['맑음', '입니다', '.']]\n"
     ]
    }
   ],
   "source": [
    "trigram = []\n",
    "\n",
    "for i in range(len(word)-2):\n",
    "    trigram.append([word[i], word[i+1], word[i+2]])\n",
    "\n",
    "print(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "space = []\n",
    "\n",
    "files = os.listdir('./data/it-life-hack/')\n",
    "\n",
    "def spacing_okt(sentence):\n",
    "    tagged = okt.pos(sentence)\n",
    "    corrected = \"\"\n",
    "    for token in tagged:\n",
    "        if token[1] in ('Josa', 'PreEomi', 'Eomi', 'Suffix', 'Punctuation'):\n",
    "            corrected += \" \" + \"'\" + token[0] + \"'\" + \",\"\n",
    "        else:\n",
    "            corrected += \" \" + \"'\" + token[0] + \"'\" + \",\"\n",
    "    if corrected[0] == \" \":\n",
    "        corrected = corrected[1:]\n",
    "    return corrected\n",
    "\n",
    "for file in files:\n",
    "    f = open('./data/it-life-hack/' + file, 'r', encoding='utf-8')\n",
    "    text = f.read()\n",
    "        \n",
    "    reg_text = re.sub(r'[0-9a-zA-Z]+', '', text)\n",
    "    reg_text = re.sub(r'[:;/+\\.-]', '', reg_text)\n",
    "    reg_text = re.sub(r'[\\s\\n]', '', reg_text)\n",
    "        \n",
    "    space.append(spacing_okt(reg_text))\n",
    "                \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "'구형', '에서', '금단', '의', '파워', '업', '!', '최신', '나', '소프트웨어', '를', '한꺼', '번', '에', '체크', '[', '플래시백', ']', '텔레비전', '이나', '와', '연', '계', '할수있는나', '프로세서', ',', '전환', '등', '재미있는가', '속속', '등장', '했다', '구형', '의', '금단', '이라고도', '할수있는', '파워', '업', '방법', '에서의', '최신', ',', '화제', '의', ',', '새로운', '보안', '소프트웨어', '까지', '한꺼', '번', '에', '소개', '합니다', '■', '인텔', '을', '에', '장착', '!', '구형', '은', '얼마나', '빨라질', '것', '인가', '?(', '위', ')', '인텔', '이', '최신', ''', '시리즈', ''', '를', '출시', '했다', '현재', '중', '에서도', '최고', '의', '성능', '을', '자랑', '하', '는', '이', '제품', '을', '구형', '의', '고속', '화', '를', '도모', '한다는', '점', '에서', '리뷰', '해보았다', '조금', '색다른', '리뷰', '가', '되지만', ',', '어느', '정도', '의', '효과', '가', '있는지', ',', '기', '대가', '크다', '■', '는사', '용하는가', '(', '인텔', '등', ')', '에서', '으로', '전환', '가능한', '하이브리드', ',', '하지', '만이', '와', '동시', '에도', '바뀐다', '■', '초기', '비용', ',', '업데이트', '비용', '모두', '무료', '!', '저스트', '시스템', ',', '도마뱀', '로그', '가', '인상', '적', '인', '보안', '소프트웨어', '현재', '는', '많은', '사용자', '들이에', '보안', '프로그램', '을', '도입', '하고', '있지만', ',', '그', '대부분', '은', '매년', ',', '엔', '정도', '드는', '업데이트', '비용', '과', '그', '절차', '에', '대해', '불만', '을', '가지', '고', '있다', '유료', '소프트웨어', '를', '이용', '하', '는', '사용자', '의약', '%', '는', '무료', '보안', '소프트웨어', '를', '알고있음에도', '불구', '하고', ',', '성능', '면', '에서', '뒤', '떨어지는게', '아니냐는', '불안', '에서', '도입', '을', '미루고있는', '상황', '이다', '■', '텔레비전', '의', '새로운', '활용', '방법', '을', '제안', '!', '의봄', '신상', '는와를', '연', '계', '는', '년월', '일', ',', '개인용', '데스크톱', '인', ''\"', '시리즈', '종류', '모델', '을', '월일', '부터', '판매', '한', '다', '고', '발표', '했다신', '상품', '은', '더', '강력해진', '녹화', '기능', '외', '에도', '시청', '·', '녹화', '기능', '에', '더해서', '업계', '최초', '로', '인기', '를', '연', '계', '한', ''', '트', '위트', '플러스', ''', '를', '추가', '하', '는', '등', '컴퓨터', '만의', '기능', '을', '탑재', '스마트폰', '홈', '네트워크', '대응', '도', '강화하고', ',\"', '안심', '간단', '쾌적', '\"', '한', '디지털', '엔터테인먼트', '를', '제안', '하', '여', ',', '주요', '모델', '에', '대해', '다음', '과', '같이', '기능', '강화', '를', '실시', '했다', '■', '마치', '축제', '같은', '출하', '식', '!', '렛츠', '노트', '출하', '시', '작', '월일', '에', '발매', '되는', ''', '의', '출하', '식', '이월', '일', '국내', '제', '조', '거점', '인', '고베', '공장', '에서', '열렸다', '동', '사의', '컴퓨터', '로는', '처음', '실시', '하', '는', '출하', '식', '으로', ',', '이', '제품', '에', '얼마나', '힘', '이', '들어가있는지', '알수있다', '[', '엡손', '정품', '잉크', ']', '잉크', '카트리지', '색', '세트', '엡손', '출판사', '입', '소문', '을', '본다',\n"
     ]
    }
   ],
   "source": [
    "print(len(space))\n",
    "print(space[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142\n",
      "   0\n",
      "0  '\n",
      "1  ,\n",
      "2   \n",
      "3  이\n",
      "4  다\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "word_freq = Counter(itertools.chain(* space))\n",
    "\n",
    "dic = []\n",
    "for word_uniq in word_freq.most_common():\n",
    "    dic.append(word_uniq[0])\n",
    "\n",
    "print(len(dic))\n",
    "print(pd.DataFrame(dic).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142\n"
     ]
    }
   ],
   "source": [
    "dic_inv = {}\n",
    "for i, word_uniq in enumerate(dic, start=1):\n",
    "    dic_inv.update({word_uniq: i})\n",
    "    \n",
    "print(len(dic_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[1, 87, 200, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 189, 129, 1, 2, 3, 1, 8, 1, 2, 3, 1, 104, 258, 1, 2, 3, 1, 153, 1, 2, 3, 1, 47, 1, 2, 3, 1, 117, 79, 1, 2, 3, 1, 57, 1, 2, 3, 1, 56, 63, 30, 292, 27, 1, 2, 3, 1, 21, 1, 2, 3, 1, 20, 547, 1, 2, 3, 1, 179, 1, 2, 3, 1, 7, 1, 2, 3, 1, 151, 72, 1, 2, 3, 1, 121, 1, 2, 3, 1, 145, 159, 24, 288, 1, 2, 3, 1, 160, 1, 2, 3, 1, 281, 109, 78, 39, 1, 2, 3, 1, 4, 57, 1, 2, 3, 1, 116, 1, 2, 3, 1, 144, 1, 2, 3, 1, 126, 1, 2, 3, 1, 53, 29, 17, 6, 57, 1, 2, 3, 1, 63, 16, 86, 22, 1, 2, 3, 1, 2, 1, 2, 3, 1, 39, 235, 1, 2, 3, 1, 70, 1, 2, 3, 1, 90, 97, 17, 6, 18, 1, 2, 3, 1, 146, 146, 1, 2, 3, 1, 70, 45, 1, 2, 3, 1, 136, 5, 1, 2, 3, 1, 87, 200, 1, 2, 3, 1, 8, 1, 2, 3, 1, 189, 129, 1, 2, 3, 1, 4, 35, 12, 19, 1, 2, 3, 1, 53, 29, 17, 6, 1, 2, 3, 1, 104, 258, 1, 2, 3, 1, 153, 1, 2, 3, 1, 161, 196, 1, 2, 3, 1, 7, 22, 8, 1, 2, 3, 1, 117, 79, 1, 2, 3, 1, 2, 1, 2, 3, 1, 65, 40, 1, 2, 3, 1, 8, 1, 2, 3, 1, 2, 1, 2, 3, 1, 198, 16, 103, 1, 2, 3, 1, 36, 114, 1, 2, 3, 1, 56, 63, 30, 292, 27, 1, 2, 3, 1, 157, 11, 1, 2, 3, 1, 20, 547, 1, 2, 3, 1, 179, 1, 2, 3, 1, 7, 1, 2, 3, 1, 56, 74, 1, 2, 3, 1, 206, 49, 5, 1, 2, 3, 1, 54, 1, 2, 3, 1, 31, 281, 1, 2, 3, 1, 10, 1, 2, 3, 1, 7, 1, 2, 3, 1, 45, 260, 1, 2, 3, 1, 47, 1, 2, 3, 1, 87, 200, 1, 2, 3, 1, 28, 1, 2, 3, 1, 301, 64, 57, 1, 2, 3, 1, 561, 35, 238, 1, 2, 3, 1, 37, 1, 2, 3, 1, 31, 18, 1, 2, 3, 1, 172, 50, 1, 2, 3, 1, 120, 1, 2, 3, 1, 51, 1, 2, 3, 1, 31, 281, 1, 2, 3, 1, 4, 1, 2, 3, 1, 117, 79, 1, 2, 3, 1, 1, 1, 2, 3, 1, 24, 23, 184, 1, 2, 3, 1, 1, 1, 2, 3, 1, 21, 1, 2, 3, 1, 131, 24, 1, 2, 3, 1, 136, 5, 1, 2, 3, 1, 186, 90, 1, 2, 3, 1, 155, 1, 2, 3, 1, 7, 22, 19, 1, 2, 3, 1, 117, 12, 1, 2, 3, 1, 8, 1, 2, 3, 1, 84, 75, 1, 2, 3, 1, 10, 1, 2, 3, 1, 32, 503, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 4, 1, 2, 3, 1, 40, 73, 1, 2, 3, 1, 10, 1, 2, 3, 1, 87, 200, 1, 2, 3, 1, 8, 1, 2, 3, 1, 12, 146, 1, 2, 3, 1, 65, 1, 2, 3, 1, 21, 1, 2, 3, 1, 19, 52, 1, 2, 3, 1, 20, 5, 6, 1, 2, 3, 1, 217, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 23, 210, 1, 2, 3, 1, 48, 36, 365, 5, 1, 2, 3, 1, 168, 189, 1, 2, 3, 1, 233, 5, 197, 1, 2, 3, 1, 23, 210, 1, 2, 3, 1, 18, 1, 2, 3, 1, 61, 11, 41, 1, 2, 3, 1, 2, 1, 2, 3, 1, 27, 321, 1, 2, 3, 1, 38, 19, 1, 2, 3, 1, 8, 1, 2, 3, 1, 356, 80, 1, 2, 3, 1, 18, 1, 2, 3, 1, 17, 6, 11, 1, 2, 3, 1, 2, 1, 2, 3, 1, 13, 1, 2, 3, 1, 33, 18, 1, 2, 3, 1, 72, 5, 1, 2, 3, 1, 54, 1, 2, 3, 1, 6, 15, 1, 2, 3, 1, 26, 9, 6, 18, 1, 2, 3, 1, 50, 1, 2, 3, 1, 31, 281, 1, 2, 3, 1, 70, 1, 2, 3, 1, 51, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 46, 16, 1, 2, 3, 1, 39, 235, 1, 2, 3, 1, 18, 75, 20, 1, 2, 3, 1, 9, 4, 244, 23, 58, 1, 2, 3, 1, 2, 1, 2, 3, 1, 9, 11, 1, 2, 3, 1, 41, 4, 1, 2, 3, 1, 116, 1, 2, 3, 1, 88, 24, 1, 2, 3, 1, 7, 19, 1, 2, 3, 1, 99, 627, 5, 1, 2, 3, 1, 54, 1, 2, 3, 1, 245, 13, 1, 2, 3, 1, 78, 26, 1, 2, 3, 1, 2, 1, 2, 3, 1, 153, 130, 4, 30, 1, 2, 3, 1, 78, 26, 1, 2, 3, 1, 52, 212, 1, 2, 3, 1, 110, 204, 1, 2, 3, 1, 47, 1, 2, 3, 1, 192, 25, 30, 1, 2, 3, 1, 24, 25, 295, 1, 2, 3, 1, 2, 1, 2, 3, 1, 19, 64, 984, 1, 2, 3, 1, 16, 42, 1, 2, 3, 1, 18, 1, 2, 3, 1, 31, 59, 1, 2, 3, 1, 82, 1, 2, 3, 1, 31, 1, 2, 3, 1, 36, 114, 1, 2, 3, 1, 56, 63, 30, 292, 27, 1, 2, 3, 1, 186, 90, 1, 2, 3, 1, 6, 1, 2, 3, 1, 263, 28, 1, 2, 3, 1, 15, 26, 32, 1, 2, 3, 1, 149, 4, 7, 1, 2, 3, 1, 36, 114, 1, 2, 3, 1, 63, 16, 42, 215, 1, 2, 3, 1, 10, 1, 2, 3, 1, 19, 76, 1, 2, 3, 1, 9, 12, 1, 2, 3, 1, 17, 11, 41, 1, 2, 3, 1, 2, 1, 2, 3, 1, 42, 1, 2, 3, 1, 33, 81, 147, 1, 2, 3, 1, 28, 1, 2, 3, 1, 122, 142, 1, 2, 3, 1, 2, 1, 2, 3, 1, 201, 1, 2, 3, 1, 38, 19, 1, 2, 3, 1, 58, 6, 1, 2, 3, 1, 153, 130, 4, 30, 1, 2, 3, 1, 78, 26, 1, 2, 3, 1, 80, 1, 2, 3, 1, 42, 1, 2, 3, 1, 289, 247, 1, 2, 3, 1, 7, 1, 2, 3, 1, 33, 48, 1, 2, 3, 1, 290, 41, 1, 2, 3, 1, 10, 1, 2, 3, 1, 18, 11, 1, 2, 3, 1, 12, 1, 2, 3, 1, 17, 5, 1, 2, 3, 1, 93, 204, 1, 2, 3, 1, 56, 63, 30, 292, 27, 1, 2, 3, 1, 21, 1, 2, 3, 1, 4, 26, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 15, 26, 32, 1, 2, 3, 1, 8, 207, 1, 2, 3, 1, 360, 1, 2, 3, 1, 6, 1, 2, 3, 1, 110, 204, 1, 2, 3, 1, 36, 114, 1, 2, 3, 1, 56, 63, 30, 292, 27, 1, 2, 3, 1, 21, 1, 2, 3, 1, 229, 12, 17, 143, 7, 19, 1, 2, 3, 1, 290, 87, 1, 2, 3, 1, 9, 12, 1, 2, 3, 1, 2, 1, 2, 3, 1, 84, 75, 1, 2, 3, 1, 44, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 495, 1, 2, 3, 1, 406, 27, 11, 6, 43, 1, 2, 3, 1, 60, 49, 900, 6, 1, 2, 3, 1, 290, 114, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 19, 76, 1, 2, 3, 1, 10, 1, 2, 3, 1, 97, 291, 12, 17, 6, 1, 2, 3, 1, 59, 401, 1, 2, 3, 1, 4, 5, 1, 2, 3, 1, 54, 1, 2, 3, 1, 281, 109, 78, 39, 1, 2, 3, 1, 8, 1, 2, 3, 1, 198, 16, 103, 1, 2, 3, 1, 231, 26, 1, 2, 3, 1, 161, 196, 1, 2, 3, 1, 10, 1, 2, 3, 1, 40, 114, 1, 2, 3, 1, 47, 1, 2, 3, 1, 8, 645, 1, 2, 3, 1, 79, 59, 1, 2, 3, 1, 6, 116, 21, 1, 2, 3, 1, 144, 1, 2, 3, 1, 126, 1, 2, 3, 1, 6, 1, 2, 3, 1, 142, 163, 1, 2, 3, 1, 34, 1, 2, 3, 1, 2, 1, 2, 3, 1, 74, 31, 26, 1, 2, 3, 1, 130, 25, 72, 593, 1, 2, 3, 1, 31, 1, 2, 3, 1, 1, 14, 1, 2, 3, 1, 24, 23, 184, 1, 2, 3, 1, 205, 357, 1, 2, 3, 1, 52, 253, 1, 2, 3, 1, 10, 1, 2, 3, 1, 163, 34, 1, 2, 3, 1, 81, 55, 1, 2, 3, 1, 173, 122, 1, 2, 3, 1, 20, 1, 2, 3, 1, 5, 1, 2, 3, 1, 12, 1, 2, 3, 1, 83, 92, 1, 2, 3, 1, 136, 5, 79, 1, 2, 3, 1, 59, 73, 1, 2, 3, 1, 28, 1, 2, 3, 1, 100, 1, 2, 3, 1, 274, 137, 48, 68, 1, 2, 3, 1, 562, 65, 1, 2, 3, 1, 13, 75, 1, 2, 3, 1, 185, 1, 2, 3, 1, 7, 19, 1, 2, 3, 1, 24, 392, 1, 2, 3, 1, 62, 1, 2, 3, 1, 562, 65, 1, 2, 3, 1, 13, 75, 1, 2, 3, 1, 7, 1, 2, 3, 1, 100, 48, 22, 1, 2, 3, 1, 153, 126, 1, 2, 3, 1, 117, 245, 1, 2, 3, 1, 16, 1, 2, 3, 1, 31, 13, 1, 2, 3, 1, 21, 1, 2, 3, 1, 144, 1, 2, 3, 1, 126, 1, 2, 3, 1, 20, 1, 2, 3, 1, 1, 1, 2, 3, 1, 30, 1, 2, 3, 1, 120, 30, 1, 2, 3, 1, 145, 101, 25, 1, 2, 3, 1, 1, 1, 2, 3, 1, 21, 1, 2, 3, 1, 222, 18, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 70, 1, 2, 3, 1, 282, 327, 55, 1, 2, 3, 1, 41, 8, 1, 2, 3, 1, 13, 75, 1, 2, 3, 1, 10, 1, 2, 3, 1, 202, 90, 1, 2, 3, 1, 25, 64, 30, 171, 1, 2, 3, 1, 458, 1, 2, 3, 1, 280, 30, 258, 72, 1, 2, 3, 1, 33, 134, 1, 2, 3, 1, 19, 1, 2, 3, 1, 274, 65, 9, 12, 1, 2, 3, 1, 2, 14, 1, 2, 3, 1, 114, 273, 1, 2, 3, 1, 138, 129, 1, 2, 3, 1, 407, 82, 1, 2, 3, 1, 14, 1, 2, 3, 1, 20, 1, 2, 3, 1, 69, 11, 154, 1, 2, 3, 1, 201, 55, 216, 31, 524, 30, 1, 2, 3, 1, 21, 1, 2, 3, 1, 40, 114, 1, 2, 3, 1, 9, 1, 2, 3, 1, 71, 1, 2, 3, 1, 2, 1, 2, 3, 1, 98, 111, 1, 2, 3, 1, 52, 253, 1, 2, 3, 1, 7, 1, 2, 3, 1, 33, 48, 1, 2, 3, 1, 5, 143, 1, 2, 3, 1, 80, 1, 2, 3, 1, 203, 4, 1, 2, 3, 1, 13, 75, 1, 2, 3, 1, 274, 65, 1, 2, 3, 1, 21, 1, 2, 3, 1, 118, 24, 1, 2, 3, 1, 136, 5, 1, 2, 3, 1, 54, 1, 2, 3, 1, 64, 96, 1, 2, 3, 1, 330, 40, 1, 2, 3, 1, 203, 28, 1, 2, 3, 1, 131, 9, 1, 2, 3, 1, 174, 1, 2, 3, 1, 47, 1, 2, 3, 1, 373, 243, 1, 2, 3, 1, 164, 30, 1, 2, 3, 1, 131, 9, 1, 2, 3, 1, 24, 1, 2, 3, 1, 67, 1, 2, 3, 1, 163, 34, 1, 2, 3, 1, 7, 1, 2, 3, 1, 83, 122, 1, 2, 3, 1, 61, 6, 1, 2, 3, 1, 1, 1, 2, 3, 1, 8, 1, 2, 3, 1, 131, 9, 1, 2, 3, 1, 174, 1, 2, 3, 1, 4, 163, 1, 2, 3, 1, 34, 1, 2, 3, 1, 211, 178, 1, 2, 3, 1, 40, 1, 2, 3, 1, 168, 1, 2, 3, 1, 139, 217, 1, 2, 3, 1, 31, 1, 2, 3, 1, 12, 536, 1, 2, 3, 1, 105, 45, 1, 2, 3, 1, 7, 22, 1, 2, 3, 1, 271, 463, 5, 1, 2, 3, 1, 88, 1, 2, 3, 1, 15, 8, 1, 2, 3, 1, 282, 327, 55, 1, 2, 3, 1, 16, 6, 1, 2, 3, 1, 230, 143, 1, 2, 3, 1, 118, 24, 1, 2, 3, 1, 9, 1, 2, 3, 1, 6, 1, 2, 3, 1, 131, 9, 1, 2, 3, 1, 174, 1, 2, 3, 1, 46, 16, 1, 2, 3, 1, 2, 1, 2, 3, 1, 4, 1, 2, 3, 1, 40, 73, 1, 2, 3, 1, 7, 1, 2, 3, 1, 301, 64, 57, 1, 2, 3, 1, 537, 1, 2, 3, 1, 4, 1, 2, 3, 1, 149, 27, 18, 17, 6, 11, 1, 2, 3, 1, 229, 29, 17, 5, 1, 2, 3, 1, 121, 1, 2, 3, 1, 601, 156, 1, 2, 3, 1, 38, 73, 1, 2, 3, 1, 381, 72, 1, 2, 3, 1, 160, 1, 2, 3, 1, 381, 72, 1, 2, 3, 1, 162, 30, 23, 11, 1, 2, 3, 1, 233, 1, 2, 3, 1, 86, 30, 1, 2, 3, 1, 601, 156, 1, 2, 3, 1, 131, 173, 15, 1, 2, 3, 1, 76, 1, 2, 3, 1, 56, 66, 1, 2, 3, 1, 10, 1, 2, 3, 1, 77, 5, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "space_id = [ [ dic_inv[word] for word in spaceWord ] for spaceWord in space ]\n",
    "\n",
    "print(len(space_id))\n",
    "print(space_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "bigram = []\n",
    "\n",
    "for i in range(len(space_id)):\n",
    "    row = space_id[i]\n",
    "    for j in range(len(row)-1):\n",
    "        tmp.append([row[j], row[j+1]])\n",
    "    bigram.extend(tmp)\n",
    "    tmp = []\n",
    "\n",
    "print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    node1  node2  weight\n",
       "10      1     12     460\n",
       "20      1     22     323\n",
       "21      1     23     247\n",
       "27      1     29     196\n",
       "28      1     30      75"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df = pd.DataFrame(bigram)\n",
    "bigram_df = bigram_df.rename(columns={0:'node1', 1:'node2'})\n",
    "\n",
    "bigram_df['weight'] = 1\n",
    "bigram_df = bigram_df.groupby(['node1', 'node2'], as_index=False).sum()\n",
    "\n",
    "bigram_df = bigram_df[bigram_df['weight'] > 10]\n",
    "bigram_df = bigram_df[bigram_df['weight'] < 500]\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 통해 가중치 10이상 500미만의 단어 페어를 추출 결과를 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
